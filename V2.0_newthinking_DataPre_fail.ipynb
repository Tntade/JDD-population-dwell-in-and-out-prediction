{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018.12.10由于很多新建的特征，对于Test并不适用，所以在V3上进行进一步整理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "640"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from datetime import date\n",
    "import datetime\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "flowdf=pd.read_csv('../data/flow_train.csv')\n",
    "trandf=pd.read_csv('../data/transition_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20180302, 20180303, 20180304, 20180305, 20180306, 20180307, 20180308, 20180309, 20180310, 20180311, 20180312, 20180313, 20180314, 20180315, 20180316]\n"
     ]
    }
   ],
   "source": [
    "start='20180301'\n",
    "dates=[]\n",
    "for i in range(1,16):\n",
    "    dd=datetime.datetime.strptime(start,\"%Y%m%d\")\n",
    "    date=dd+datetime.timedelta(days=i)\n",
    "    dates.append(int(datetime.datetime.strftime(date,\"%Y%m%d\")))\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "trandf['start_address']=trandf['o_city_code'].astype(str)+':'+trandf['o_district_code'].astype(str)\n",
    "trandf['end_address']=trandf['d_city_code'].astype(str)+':'+trandf['d_district_code'].astype(str)\n",
    "\n",
    "flowdf['address']=flowdf['city_code'].astype(str)+':'+flowdf['district_code'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_address=list(set(trandf['start_address']))\n",
    "end_address=list(set(trandf['end_address']))\n",
    "# print(len(set(start_address)&set(end_address)))\n",
    "# print(len(start_address))\n",
    "# print(len(end_address))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ==========没办法，得先建立个testdf，否则脑子转不动===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### / 代表了除号  \n",
    "### % 代表了取余"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142590, 4)\n"
     ]
    }
   ],
   "source": [
    "def get_df(k=98,add_list=start_address):\n",
    "    df=pd.DataFrame()\n",
    "    df['row_id']=np.arange(9604)\n",
    "    df['start_address']='0'\n",
    "    df['end_address']='0'\n",
    "    for i in range(0,9603,98):\n",
    "        df['start_address'][i:(i+k)]=add_list[int(i/k)]\n",
    "        for index in range(i,i+k):\n",
    "            df.loc[index,'end_address']=add_list[int(index%k)]\n",
    "    return df\n",
    "\n",
    "test=get_df(k=98,add_list=start_address)\n",
    "test['date_dt']=dates[0]\n",
    "\n",
    "for i in range(1,15,1):\n",
    "    df=get_df(k=98,add_list=start_address)\n",
    "    df['date_dt']=dates[i]\n",
    "    test=pd.concat([test,df],axis=0)\n",
    "    del df\n",
    "    gc.collect()\n",
    "\n",
    "test=test[test['start_address']!=test['end_address']]\n",
    "print(test.shape)\n",
    "\n",
    "del test['row_id']\n",
    "\n",
    "test['o_city_code']=test['start_address'].apply(lambda x:str(x).split(':')[0])\n",
    "test['o_district_code']=test['start_address'].apply(lambda x:str(x).split(':')[1])\n",
    "test['d_city_code']=test['end_address'].apply(lambda x:str(x).split(':')[0])\n",
    "test['d_district_code']=test['end_address'].apply(lambda x:str(x).split(':')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==========哦哟，以上终于建立好了Testdf========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def month(date):\n",
    "    date=str(date)\n",
    "    return int(date[4:6])\n",
    "\n",
    "def day(date):\n",
    "    date=str(date)\n",
    "    return int(date[6:8])\n",
    "\n",
    "def weekd(date):\n",
    "    date=str(date)\n",
    "    return str(datetime.strptime(date,'%Y%m%d').weekday())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "trandf['month']=trandf['date_dt'].apply(month)\n",
    "trandf['month']=trandf['month'].apply(lambda x:int(x+12) if x <4 else x)\n",
    "trandf['day']=trandf['date_dt'].apply(day)\n",
    "trandf['weekd']=trandf['date_dt'].apply(weekd)\n",
    "\n",
    "test['month']=test['date_dt'].apply(month)\n",
    "test['month']=test['month'].apply(lambda x:int(x+12) if x<4 else x)\n",
    "test['day']=test['date_dt'].apply(day)\n",
    "test['weekd']=test['date_dt'].apply(weekd)\n",
    "test['cnt']=0\n",
    "\n",
    "flowdf['month']=flowdf['date_dt'].apply(month)\n",
    "flowdf['month']=flowdf['month'].apply(lambda x:int(x+12) if x <4 else x)\n",
    "flowdf['day']=flowdf['date_dt'].apply(day)\n",
    "flowdf['weekd']=flowdf['date_dt'].apply(weekd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对于这个address,流进与流出谁大呢？可以用于flowdf中的特征！！！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========数据合并后一起处理======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat([trandf,test],axis=0)\n",
    "data['cnt']=round(data['cnt'],6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "#标签数值化\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "\n",
    "le.fit(data['o_city_code'])\n",
    "data['o_city_code']=le.transform(data['o_city_code'])\n",
    "data['d_city_code']=le.transform(data['d_city_code'])\n",
    "\n",
    "le.fit(data['o_district_code'])\n",
    "data['o_district_code']=le.transform(data['o_district_code'])\n",
    "data['d_district_code']=le.transform(data['d_district_code'])\n",
    "\n",
    "le.fit(data['start_address'])\n",
    "data['start_address']=le.transform(data['start_address'])\n",
    "flowdf['address']=le.transform(flowdf['address'])\n",
    "data['end_address']=le.transform(data['end_address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数值onehotcoding,维度太高机器跑不动\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# hot=OneHotEncoder()\n",
    "# hot_col=['month','day','weekd','o_city_code','o_district_code','d_city_code','d_district_code']\n",
    "# for fea in hot_col:\n",
    "#     data[fea+'_hot']=hot.fit_transform(data[[fea]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=red>基本特征准备<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue>mean  ·  nunique ·  count特征<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2622910, 19)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "409"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timefea=['day','weekd']\n",
    "addfea=['start_address','end_address']\n",
    "\n",
    "#时间一维\n",
    "for tf in timefea:\n",
    "    temp=data[[tf,'cnt']]\n",
    "    meandf=temp.groupby(tf).cnt.mean().reset_index(name=tf+'_cnt_mean')\n",
    "    nundf=temp.groupby('cnt')[tf].nunique().reset_index(name=tf+'_nun')\n",
    "    cntdf=temp.groupby('cnt')[tf].count().reset_index(name='cnt_'+tf+'_count')\n",
    "    cntdf1=temp.groupby(tf).cnt.count().reset_index(name=tf+'_cnt_count')\n",
    "    \n",
    "    data=data.merge(meandf,on=tf,how='left')\n",
    "    data=data.merge(nundf,on='cnt',how='left')\n",
    "    data=data.merge(cntdf,on='cnt',how='left')\n",
    "    data=data.merge(cntdf1,on=tf,how='left')\n",
    "print(data.shape)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2622910, 27)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#地址一维\n",
    "for af in addfea:\n",
    "    temp=data[[af,'cnt']]\n",
    "    meandf=temp.groupby(af).cnt.mean().reset_index(name=af+'_cnt_mean')\n",
    "    nundf=temp.groupby('cnt')[af].nunique().reset_index(name=af+'_nun')\n",
    "    cntdf=temp.groupby(af).cnt.count().reset_index(name=af+'_cnt_count')\n",
    "    cntdf1=temp.groupby('cnt')[af].count().reset_index(name='cnt_'+af+'_count')\n",
    "\n",
    "    data=data.merge(meandf,on=af,how='left')\n",
    "    data=data.merge(cntdf,on=af,how='left')\n",
    "    data=data.merge(nundf,on='cnt',how='left')\n",
    "    data=data.merge(cntdf1,on='cnt',how='left')\n",
    "print(data.shape)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2622910, 32)\n"
     ]
    }
   ],
   "source": [
    "#时间二维\n",
    "temp=data[['cnt','day','weekd']]\n",
    "meandf=temp.groupby(['day','weekd']).cnt.mean().reset_index(name='day_week_cnt_mean')\n",
    "cntdf1=temp.groupby(['day','weekd']).cnt.count().reset_index(name='day_week__cnt_count')\n",
    "cntdf2=temp.groupby(['cnt','day']).cnt.count().reset_index(name='cnt_day_count')\n",
    "# cntdf3=tmp.groupby(['cnt','day']).day.count().reset_index(name='cnt_day_day_count') #与上面的相等\n",
    "cntdf3=temp.groupby(['cnt','weekd']).cnt.count().reset_index(name='cnt_week_count')\n",
    "cntdf4=temp.groupby(['cnt','day','weekd']).cnt.count().reset_index(name='cnt_day_week_count')\n",
    "\n",
    "data=data.merge(meandf,on=['day','weekd'],how='left')\n",
    "data=data.merge(cntdf1,on=['day','weekd'],how='left')\n",
    "data=data.merge(cntdf2,on=['cnt','day'],how='left')\n",
    "data=data.merge(cntdf3,on=['cnt','weekd'],how='left')\n",
    "data=data.merge(cntdf4,on=['cnt','day','weekd'],how='left')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2622910, 35)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "301"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#地址二维\n",
    "temp=data[['cnt','start_address','end_address']]\n",
    "meandf=temp.groupby(['start_address','end_address']).cnt.mean().reset_index(name='start_end_cnt_mean')\n",
    "cntdf=temp.groupby(['start_address','end_address']).cnt.count().reset_index(name='start_end_cnt_count')\n",
    "# cntdf1=temp.groupby(['cnt','start_address']).cnt.count().reset_index(name='cnt_str_count')\n",
    "# cntdf2=temp.groupby(['cnt','end_address']).cnt.count().reset_index(name='cnt_end_count')\n",
    "cntdf3=temp.groupby(['cnt','start_address','end_address']).cnt.count().reset_index(name='cnt_str_end_count')\n",
    "\n",
    "data=data.merge(meandf,on=['start_address','end_address'],how='left')\n",
    "data=data.merge(cntdf,on=['start_address','end_address'],how='left')\n",
    "data=data.merge(cntdf3,on=['cnt','start_address','end_address'],how='left')\n",
    "print(data.shape)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2622910, 47)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #时间地址交叉维度\n",
    "for tf in timefea:\n",
    "    for af in addfea:\n",
    "        temp=data[[tf,af,'cnt']]\n",
    "        meandf=temp.groupby([tf,af]).cnt.mean().reset_index(name=tf+'_'+af+'_cnt_mean')\n",
    "        cntdf=temp.groupby([tf,af]).cnt.count().reset_index(name=tf+'_'+af+'_cnt_count')\n",
    "        cntdf1=temp.groupby(['cnt',tf,af]).cnt.count().reset_index(name='cnt_'+tf+af+'_count')\n",
    "        data=data.merge(meandf,on=[tf,af],how='left')\n",
    "        data=data.merge(cntdf,on=[tf,af],how='left')\n",
    "        data=data.merge(cntdf1,on=['cnt',tf,af],how='left')\n",
    "print(data.shape)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2622910, 51)\n"
     ]
    }
   ],
   "source": [
    "#时间二维与单地址的交叉\n",
    "for af in addfea:\n",
    "    temp=data[['day','weekd',af,'cnt']]\n",
    "    meandf=temp.groupby(['day','weekd',af]).cnt.mean().reset_index(name='day_week_'+af+'_cnt_mean')\n",
    "    cntdf=temp.groupby(['day','weekd',af]).cnt.count().reset_index(name='day_week_'+af+'_cnt_count')\n",
    "    data=data.merge(meandf,on=['day','weekd',af],how='left')\n",
    "    data=data.merge(cntdf,on=['day','weekd',af],how='left')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2622910, 53)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "230"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#时间二维与地址二维度的交叉\n",
    "temp=data[['day','weekd','start_address','end_address','cnt']]\n",
    "meandf=temp.groupby(['day','weekd','start_address','end_address']).cnt.mean().reset_index(name='day_week_st_end_cnt_mean')\n",
    "cntdf=temp.groupby(['day','weekd','start_address','end_address']).cnt.count().reset_index(name='day_week_st_end_cnt_count')\n",
    "data=data.merge(meandf,on=['day','weekd','start_address','end_address'],how='left')\n",
    "data=data.merge(cntdf,on=['day','weekd','start_address','end_address'],how='left')\n",
    "print(data.shape)\n",
    "del temp\n",
    "del meandf\n",
    "del nundf\n",
    "del cntdf\n",
    "del cntdf1\n",
    "del cntdf2\n",
    "del cntdf3\n",
    "del cntdf4\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 历史转移率特征，来挖掘历史转移信息，同时防止过拟合（参考历史点击率特征）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_address  over\n",
      "end_address  over\n",
      "(2622910, 56)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "422"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['period'] = data['month']\n",
    "for feat_1 in addfea:\n",
    "    res = pd.DataFrame()\n",
    "    temp = data[[feat_1, 'period', 'cnt']]\n",
    "    for period in range(6, 16):\n",
    "        if period == 6:\n",
    "            count = temp.groupby([feat_1]).apply(\n",
    "                lambda x: x['cnt'][(x['period'] <= period).values].count()).reset_index(name=feat_1 + '_all')\n",
    "            count1 = temp.groupby([feat_1]).apply(\n",
    "                lambda x: x['cnt'][(x['period'] <= period).values].sum()).reset_index(name=feat_1 + '_1')\n",
    "        else:\n",
    "            count = temp.groupby([feat_1]).apply(\n",
    "                lambda x: x['cnt'][(x['period'] < period).values].count()).reset_index(name=feat_1 + '_all')\n",
    "            count1 = temp.groupby([feat_1]).apply(\n",
    "                lambda x: x['cnt'][(x['period'] < period).values].sum()).reset_index(name=feat_1 + '_1')\n",
    "        count[feat_1 + '_1'] = count1[feat_1 + '_1']\n",
    "        count.fillna(value=0, inplace=True)\n",
    "        count[feat_1 + '_rate'] = round(count[feat_1 + '_1'] / count[feat_1 + '_all'], 6)\n",
    "        count['period'] = period\n",
    "        count.drop([feat_1 + '_all', feat_1 + '_1'], axis=1, inplace=True)\n",
    "        count.fillna(value=0, inplace=True)\n",
    "        res = res.append(count, ignore_index=True)\n",
    "    print(feat_1, ' over')\n",
    "    data = pd.merge(data, res, how='left', on=[feat_1, 'period'])\n",
    "print(data.shape)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_address  over\n",
      "end_address  over\n",
      "(2622910, 58)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1205"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['period'] = data['day']\n",
    "for feat_1 in addfea:\n",
    "    res = pd.DataFrame()\n",
    "    temp = data[[feat_1, 'period', 'cnt']]\n",
    "    for period in range(1, 32):\n",
    "        if period == 1:\n",
    "            count = temp.groupby([feat_1]).apply(\n",
    "                lambda x: x['cnt'][(x['period'] <= period).values].count()).reset_index(name=feat_1 + '_all')\n",
    "            count1 = temp.groupby([feat_1]).apply(\n",
    "                lambda x: x['cnt'][(x['period'] <= period).values].sum()).reset_index(name=feat_1 + '_1')\n",
    "        else:\n",
    "            count = temp.groupby([feat_1]).apply(\n",
    "                lambda x: x['cnt'][(x['period'] < period).values].count()).reset_index(name=feat_1 + '_all')\n",
    "            count1 = temp.groupby([feat_1]).apply(\n",
    "                lambda x: x['cnt'][(x['period'] < period).values].sum()).reset_index(name=feat_1 + '_1')\n",
    "        count[feat_1 + '_1'] = count1[feat_1 + '_1']\n",
    "        count.fillna(value=0, inplace=True)\n",
    "        count[feat_1 + '_rate'] = round(count[feat_1 + '_1'] / count[feat_1 + '_all'], 6)\n",
    "        count['period'] = period\n",
    "        count.drop([feat_1 + '_all', feat_1 + '_1'], axis=1, inplace=True)\n",
    "        count.fillna(value=0, inplace=True)\n",
    "        res = res.append(count, ignore_index=True)\n",
    "    print(feat_1, ' over')\n",
    "    data = pd.merge(data, res, how='left', on=[feat_1, 'period'])\n",
    "print(data.shape)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_address  over\n",
      "end_address  over\n",
      "(2622910, 60)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "641"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['period'] = data['weekd'].astype(int)\n",
    "for feat_1 in addfea:\n",
    "    res = pd.DataFrame()\n",
    "    temp = data[[feat_1, 'period', 'cnt']]\n",
    "    for period in range(0, 7):\n",
    "        if period == 0:\n",
    "            count = temp.groupby([feat_1]).apply(\n",
    "                lambda x: x['cnt'][(x['period'] <= period).values].count()).reset_index(name=feat_1 + '_all')\n",
    "            count1 = temp.groupby([feat_1]).apply(\n",
    "                lambda x: x['cnt'][(x['period'] <= period).values].sum()).reset_index(name=feat_1 + '_1')\n",
    "        else:\n",
    "            count = temp.groupby([feat_1]).apply(\n",
    "                lambda x: x['cnt'][(x['period'] < period).values].count()).reset_index(name=feat_1 + '_all')\n",
    "            count1 = temp.groupby([feat_1]).apply(\n",
    "                lambda x: x['cnt'][(x['period'] < period).values].sum()).reset_index(name=feat_1 + '_1')\n",
    "        count[feat_1 + '_1'] = count1[feat_1 + '_1']\n",
    "        count.fillna(value=0, inplace=True)\n",
    "        count[feat_1 + '_rate'] = round(count[feat_1 + '_1'] / count[feat_1 + '_all'], 6)\n",
    "        count['period'] = period\n",
    "        count.drop([feat_1 + '_all', feat_1 + '_1'], axis=1, inplace=True)\n",
    "        count.fillna(value=0, inplace=True)\n",
    "        res = res.append(count, ignore_index=True)\n",
    "    print(feat_1, ' over')\n",
    "    data = pd.merge(data, res, how='left', on=[feat_1, 'period'])\n",
    "print(data.shape)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 不行了，随便挖掘几个Ration特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ration:day/weekd偏好的ration比例特征（如1号从1地转移的cnt sum占1号所有转移的cnt sum比例）\n",
    "# 1号那天的Cnt sum/all day cnt sum,该特征舍弃\n",
    "\n",
    "# 1号那天,1地出发的cnt sum/1号那天all地出发的cnt sum\n",
    "# on='day','start_address'\n",
    "\n",
    "# 1号那天,1地出发,到达2地的cnt sum/1号那天，1地出发，到达all地的cnt sum\n",
    "# on='day','start_address','end_address'\n",
    "\n",
    "\n",
    "# 0weekd那天的Cnt sum/all weekd cnt sum\n",
    "\n",
    "# 0weekd那天,1地出发的cnt sum/0weekd那天all地出发的cnt sum\n",
    "\n",
    "# 0weekd那天,1地出发,到达2地的cnt sum/0weekd那天，1地出发，到达all地的cnt sum\n",
    "\n",
    "\n",
    "# temp=data[['cnt','day']].groupby('day').cnt.sum().reset_index(name='day_sum')\n",
    "# data=merge(temp,on='day',how='left')\n",
    "# data['day_ration']=data['cnt']/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 来一波像模像样的特征选择吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 方差检验\n",
    "# np.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 单变量特征选择 (Univariate feature selection)\n",
    "# 　　单变量特征选择的原理是分别单独的计算每个变量的某个统计指标，根据该指标来判断哪些指标重要，\n",
    "#     剔除那些不重要的指标。\n",
    "# 　　对于分类问题(y离散)，可采用：\n",
    "# 　　　　卡方检验，f_classif, mutual_info_classif，互信息\n",
    "# 　　对于回归问题(y连续)，可采用：\n",
    "# 　　　　皮尔森相关系数，f_regression, mutual_info_regression，最大信息系数\n",
    "    \n",
    "#     这种方法比较简单，易于运行，易于理解，通常对于理解数据有较好的效果（但对特征优化、提高泛化能力来说不一定有效）。\n",
    "#     这种方法有许多改进的版本、变种。\n",
    "# 　　单变量特征选择基于单变量的统计测试来选择最佳特征。\n",
    "# 它可以看作预测模型的一项预处理。\n",
    "# ==Scikit-learn将特征选择程序用包含 transform 函数的对象来展现==：\n",
    "# •\tSelectKBest 移除得分前 k 名以外的所有特征(取top k)\n",
    "# •\tSelectPercentile 移除得分在用户指定百分比以后的特征(取top k%)\n",
    "\n",
    "# 将特征输入到评分函数，返回一个单变量的f_score(F检验的值)或p-values(P值，假设检验中的一个标准，P-value用来和显著性水平作比较)，注意SelectKBest 和 SelectPercentile只有得分，没有p-value。\n",
    "# •\tFor classification: chi2, f_classif, mutual_info_classif\n",
    "# •\tFor regression: f_regression, mutual_info_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特征选择参考\n",
    "# user_tags特征我们分别用了卡方检验和特征重要性。\n",
    "# train_new = pd.DataFrame()\n",
    "# test_new = pd.DataFrame()\n",
    "# cntv = CountVectorizer()\n",
    "# cntv.fit(data['user_tags'])\n",
    "# train_a = cntv.transform(train['user_tags'])\n",
    "# test_a = cntv.transform(test['user_tags'])\n",
    "# train_new = sparse.hstack((train_new, train_a), 'csr', 'bool')\n",
    "# test_new = sparse.hstack((test_new, test_a), 'csr', 'bool')\n",
    "# # 卡方检验\n",
    "# SKB = SelectPercentile(chi2, percentile=95).fit(train_new, train_y)\n",
    "# train_new = SKB.transform(train_new)\n",
    "# test_new = SKB.transform(test_new)\n",
    "\n",
    "\n",
    "# size = 300\n",
    "# x = np.random.normal(0, 1, size)\n",
    "# # pearsonr(x, y)的输入为特征矩阵和目标向量\n",
    "# print(\"Lower noise\", pearsonr(x,y))\n",
    "# print(\"Higher noise\", pearsonr(x, y))\n",
    "# 这个例子中，我们比较了变量在加入噪音之前和之后的差异。当噪音比较小的时候，相关性很强，p-value很低。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import SelectKBest\n",
    "# from scipy.stats import pearsonr\n",
    "# train_new=\n",
    "# train_y=\n",
    "# test_new=\n",
    "# SKB = SelectPercentile(f_regression, percentile=80).fit(train_new, train_y)\n",
    "# train_new = SKB.transform(train_new)\n",
    "# test_new = SKB.transform(test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型重要性，或者 三个模型的重要性排序后取交集 或并集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 蛇佬的贪心算法+退火算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# =========准备模型========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "#实数序列数据预测问题，可以使用平方根误差\n",
    "# def rmse(y_true,y_pred):\n",
    "#     rmse=round(np.sqrt(np.average((y_pred-np.array(y_true))**2)),5)\n",
    "#     return rmse\n",
    "\n",
    "\n",
    "#这个评估标准是大赛规定的\n",
    "def rmsle(y_true, y_pred):\n",
    "    return 'RMSLE', round(np.sqrt(np.mean(np.power(np.log1p(y_pred) - np.log1p(y_true), 2))),5), False\n",
    "\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "#也可以使用mse评价标准"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ======按照出发城市进行分集存储后提取训练==============\n",
    "\n",
    "#按照出发城市进行分集存储\n",
    "def save_data(path,data):\n",
    "    for i in range(0,7):\n",
    "        ndata=data[data['o_city_code']==i]\n",
    "        ndata.to_csv(path+'data_'+str(i)+'.csv',index=False)\n",
    "        \n",
    "path='../data/'\n",
    "save_data(path,data)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def count_corr(df):\n",
    "#     '''\n",
    "#     输入dataframe\n",
    "#     输出相关系数dataframe:col_1,col_2,cor(不包含同一特征且已去重复)\n",
    "#     '''\n",
    "#     x = df.corr().abs().unstack().sort_values(ascending=False).reset_index()\n",
    "#     x = x.loc[x.level_0!=x.level_1]\n",
    "#     x2 = pd.DataFrame([sorted(i) for i in x[['level_0','level_1']].values])\n",
    "#     x2['cor'] = x[0].values\n",
    "#     x2.columns = ['col_1','col_2','cor']\n",
    "#     return x2.drop_duplicates()\n",
    "\n",
    "# testn=count_corr(test)\n",
    "\n",
    "# print(testn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#由于2018年3月，仅仅出现了1天的已知数据，其他15天均需要预测的，\n",
    "# ，故将3月亦作为test1数据，然后将test1_true,与test1_pred作对比，3月为年后交通高峰，所以可以普遍加一个定数cnt\n",
    "# ，或者根据start_address来进行加一定的数后，便是最后的3.2-3.16的预测cnt了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class lightgbm.LGBMRegressor(boosting_type='gbdt', num_leaves=31, max_depth=-1, learning_rate=0.1, \n",
    "#                              n_estimators=100, subsample_for_bin=200000, objective=None, class_weight=None, \n",
    "#                              min_split_gain=0.0, min_child_weight=0.001, min_child_samples=20, subsample=1.0, \n",
    "#                              subsample_freq=0, colsample_bytree=1.0, reg_alpha=0.0, reg_lambda=0.0, \n",
    "#                              random_state=None, n_jobs=-1, silent=True, importance_type='split', **kwargs)\n",
    "\n",
    "def get_lgb(path,i,N):\n",
    "    data=pd.read_csv(path+'data_'+str(i)+'.csv')\n",
    "    train=data[data['cnt']!=0][data['month']!=15]\n",
    "    test=data[data['cnt']==0]\n",
    "    test1=data[data['cnt']!=0][data['month']==15]\n",
    "    test1['month']=11\n",
    "    print(train.shape,test.shape,test1.shape)\n",
    "    \n",
    "    train_xy,off_xy=train_test_split(train,test_size=0.1,random_state=1)\n",
    "    tr,val=train_test_split(train_xy,test_size=0.15,random_state=1)\n",
    "    \n",
    "    drop_list=['cnt','o_city_code','date_dt']\n",
    "    y_train=tr.cnt\n",
    "    x_train=tr.drop(drop_list,axis=1)\n",
    "    \n",
    "    y_val=val.cnt\n",
    "    x_val=val.drop(drop_list,axis=1)\n",
    "    \n",
    "    y_off=off_xy.cnt\n",
    "    x_off=off_xy.drop(drop_list,axis=1)\n",
    "    \n",
    "    test_x=test.drop(drop_list,axis=1)\n",
    "    test_x1=test1.drop(drop_list,axis=1)\n",
    "\n",
    "    gbm = lgb.LGBMRegressor(objective='regression',\n",
    "                        num_leaves=50,\n",
    "                        learning_rate=0.05,\n",
    "                        n_estimators=N)\n",
    "\n",
    "    gbm.fit(x_train, y_train,\n",
    "        eval_set=[(x_train,y_train),(x_val,y_val)],\n",
    "        eval_metric='l1',\n",
    "        early_stopping_rounds=50)\n",
    "\n",
    "    y_pred = gbm.predict(x_val, num_iteration=gbm.best_iteration_)\n",
    "    y_eval=rmsle(y_val,y_pred)[1]\n",
    "    # print('The rmse of prediction is:', mean_squared_error(y_val, y_pred) ** 0.5)\n",
    "    print('The rmlse of prediction is:',y_eval)\n",
    "    # print('Feature importances:', list(gbm.feature_importances_))\n",
    "\n",
    "    y_pred_off=gbm.predict(x_off,num_iteration=gbm.best_iteration_)\n",
    "    y_off_eval=rmsle(y_off, y_pred_off)[1]\n",
    "    # print('The rmse of prediction is:', mean_squared_error(y_off, y_pred_off) ** 0.5)\n",
    "    print('The rmlse of prediction is:',y_off_eval)\n",
    "\n",
    "    gc.collect()\n",
    "    \n",
    "    test['cnt']=gbm.predict(test_x,num_iteration=gbm.best_iteration_)\n",
    "    \n",
    "    data=pd.concat([train,test],axis=0)\n",
    "    data.to_csv(path+'dataf_'+str(i)+'.csv',index=False)\n",
    "    \n",
    "    return y_eval,y_off_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569813, 11) (32010, 11)\n",
      "[1]\ttraining's l1: 2.0359\tvalid_1's l1: 2.05213\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\ttraining's l1: 1.97385\tvalid_1's l1: 1.98925\n",
      "[3]\ttraining's l1: 1.9142\tvalid_1's l1: 1.92863\n",
      "[4]\ttraining's l1: 1.85798\tvalid_1's l1: 1.87192\n",
      "[5]\ttraining's l1: 1.80587\tvalid_1's l1: 1.81928\n",
      "[6]\ttraining's l1: 1.7558\tvalid_1's l1: 1.76869\n",
      "[7]\ttraining's l1: 1.70887\tvalid_1's l1: 1.72125\n",
      "[8]\ttraining's l1: 1.66306\tvalid_1's l1: 1.67495\n",
      "[9]\ttraining's l1: 1.61885\tvalid_1's l1: 1.63\n",
      "[10]\ttraining's l1: 1.57942\tvalid_1's l1: 1.59038\n",
      "[11]\ttraining's l1: 1.54075\tvalid_1's l1: 1.55161\n",
      "[12]\ttraining's l1: 1.50447\tvalid_1's l1: 1.51515\n",
      "[13]\ttraining's l1: 1.47095\tvalid_1's l1: 1.4817\n",
      "[14]\ttraining's l1: 1.43872\tvalid_1's l1: 1.44934\n",
      "[15]\ttraining's l1: 1.40648\tvalid_1's l1: 1.41702\n",
      "[16]\ttraining's l1: 1.37834\tvalid_1's l1: 1.38887\n",
      "[17]\ttraining's l1: 1.34956\tvalid_1's l1: 1.36002\n",
      "[18]\ttraining's l1: 1.32299\tvalid_1's l1: 1.33336\n",
      "[19]\ttraining's l1: 1.29764\tvalid_1's l1: 1.30787\n",
      "[20]\ttraining's l1: 1.27474\tvalid_1's l1: 1.2849\n",
      "[21]\ttraining's l1: 1.25315\tvalid_1's l1: 1.26315\n",
      "[22]\ttraining's l1: 1.23271\tvalid_1's l1: 1.24257\n",
      "[23]\ttraining's l1: 1.21298\tvalid_1's l1: 1.22265\n",
      "[24]\ttraining's l1: 1.19488\tvalid_1's l1: 1.2044\n",
      "[25]\ttraining's l1: 1.17712\tvalid_1's l1: 1.1866\n",
      "[26]\ttraining's l1: 1.15977\tvalid_1's l1: 1.16927\n",
      "[27]\ttraining's l1: 1.14361\tvalid_1's l1: 1.15308\n",
      "[28]\ttraining's l1: 1.12939\tvalid_1's l1: 1.13902\n",
      "[29]\ttraining's l1: 1.11441\tvalid_1's l1: 1.12433\n",
      "[30]\ttraining's l1: 1.0993\tvalid_1's l1: 1.10913\n",
      "[31]\ttraining's l1: 1.08489\tvalid_1's l1: 1.09492\n",
      "[32]\ttraining's l1: 1.07045\tvalid_1's l1: 1.08048\n",
      "[33]\ttraining's l1: 1.05796\tvalid_1's l1: 1.06809\n",
      "[34]\ttraining's l1: 1.04552\tvalid_1's l1: 1.05595\n",
      "[35]\ttraining's l1: 1.03346\tvalid_1's l1: 1.04389\n",
      "[36]\ttraining's l1: 1.02166\tvalid_1's l1: 1.03204\n",
      "[37]\ttraining's l1: 1.01118\tvalid_1's l1: 1.02145\n",
      "[38]\ttraining's l1: 1.00088\tvalid_1's l1: 1.01122\n",
      "[39]\ttraining's l1: 0.990673\tvalid_1's l1: 1.00097\n",
      "[40]\ttraining's l1: 0.979853\tvalid_1's l1: 0.990103\n",
      "[41]\ttraining's l1: 0.972154\tvalid_1's l1: 0.982339\n",
      "[42]\ttraining's l1: 0.960765\tvalid_1's l1: 0.970671\n",
      "[43]\ttraining's l1: 0.952002\tvalid_1's l1: 0.961903\n",
      "[44]\ttraining's l1: 0.944281\tvalid_1's l1: 0.954196\n",
      "[45]\ttraining's l1: 0.936666\tvalid_1's l1: 0.94663\n",
      "[46]\ttraining's l1: 0.929998\tvalid_1's l1: 0.940037\n",
      "[47]\ttraining's l1: 0.921897\tvalid_1's l1: 0.931995\n",
      "[48]\ttraining's l1: 0.914733\tvalid_1's l1: 0.925011\n",
      "[49]\ttraining's l1: 0.909361\tvalid_1's l1: 0.919605\n",
      "[50]\ttraining's l1: 0.901849\tvalid_1's l1: 0.912134\n",
      "[51]\ttraining's l1: 0.896406\tvalid_1's l1: 0.906662\n",
      "[52]\ttraining's l1: 0.891095\tvalid_1's l1: 0.90138\n",
      "[53]\ttraining's l1: 0.8865\tvalid_1's l1: 0.896822\n",
      "[54]\ttraining's l1: 0.879863\tvalid_1's l1: 0.890291\n",
      "[55]\ttraining's l1: 0.874682\tvalid_1's l1: 0.88507\n",
      "[56]\ttraining's l1: 0.868112\tvalid_1's l1: 0.878414\n",
      "[57]\ttraining's l1: 0.863874\tvalid_1's l1: 0.874258\n",
      "[58]\ttraining's l1: 0.860385\tvalid_1's l1: 0.87083\n",
      "[59]\ttraining's l1: 0.854849\tvalid_1's l1: 0.86536\n",
      "[60]\ttraining's l1: 0.849508\tvalid_1's l1: 0.859869\n",
      "[61]\ttraining's l1: 0.845711\tvalid_1's l1: 0.856158\n",
      "[62]\ttraining's l1: 0.840146\tvalid_1's l1: 0.850596\n",
      "[63]\ttraining's l1: 0.83761\tvalid_1's l1: 0.848025\n",
      "[64]\ttraining's l1: 0.831527\tvalid_1's l1: 0.841931\n",
      "[65]\ttraining's l1: 0.826383\tvalid_1's l1: 0.836609\n",
      "[66]\ttraining's l1: 0.823859\tvalid_1's l1: 0.834162\n",
      "[67]\ttraining's l1: 0.818251\tvalid_1's l1: 0.828624\n",
      "[68]\ttraining's l1: 0.814585\tvalid_1's l1: 0.824918\n",
      "[69]\ttraining's l1: 0.809375\tvalid_1's l1: 0.819763\n",
      "[70]\ttraining's l1: 0.806192\tvalid_1's l1: 0.816706\n",
      "[71]\ttraining's l1: 0.803625\tvalid_1's l1: 0.81425\n",
      "[72]\ttraining's l1: 0.798778\tvalid_1's l1: 0.809364\n",
      "[73]\ttraining's l1: 0.793287\tvalid_1's l1: 0.803945\n",
      "[74]\ttraining's l1: 0.790828\tvalid_1's l1: 0.801572\n",
      "[75]\ttraining's l1: 0.785595\tvalid_1's l1: 0.79638\n",
      "[76]\ttraining's l1: 0.783119\tvalid_1's l1: 0.794\n",
      "[77]\ttraining's l1: 0.778524\tvalid_1's l1: 0.789487\n",
      "[78]\ttraining's l1: 0.776594\tvalid_1's l1: 0.787572\n",
      "[79]\ttraining's l1: 0.771407\tvalid_1's l1: 0.782305\n",
      "[80]\ttraining's l1: 0.766807\tvalid_1's l1: 0.777645\n",
      "[81]\ttraining's l1: 0.764567\tvalid_1's l1: 0.77548\n",
      "[82]\ttraining's l1: 0.760129\tvalid_1's l1: 0.770992\n",
      "[83]\ttraining's l1: 0.756793\tvalid_1's l1: 0.767712\n",
      "[84]\ttraining's l1: 0.754948\tvalid_1's l1: 0.76597\n",
      "[85]\ttraining's l1: 0.750168\tvalid_1's l1: 0.761085\n",
      "[86]\ttraining's l1: 0.74778\tvalid_1's l1: 0.758772\n",
      "[87]\ttraining's l1: 0.745774\tvalid_1's l1: 0.756846\n",
      "[88]\ttraining's l1: 0.742131\tvalid_1's l1: 0.753175\n",
      "[89]\ttraining's l1: 0.739584\tvalid_1's l1: 0.750695\n",
      "[90]\ttraining's l1: 0.736503\tvalid_1's l1: 0.747594\n",
      "[91]\ttraining's l1: 0.734605\tvalid_1's l1: 0.745748\n",
      "[92]\ttraining's l1: 0.732669\tvalid_1's l1: 0.743723\n",
      "[93]\ttraining's l1: 0.729466\tvalid_1's l1: 0.740603\n",
      "[94]\ttraining's l1: 0.725315\tvalid_1's l1: 0.736399\n",
      "[95]\ttraining's l1: 0.723604\tvalid_1's l1: 0.734766\n",
      "[96]\ttraining's l1: 0.721466\tvalid_1's l1: 0.732765\n",
      "[97]\ttraining's l1: 0.718622\tvalid_1's l1: 0.729879\n",
      "[98]\ttraining's l1: 0.715236\tvalid_1's l1: 0.726445\n",
      "[99]\ttraining's l1: 0.713863\tvalid_1's l1: 0.725087\n",
      "[100]\ttraining's l1: 0.711518\tvalid_1's l1: 0.722859\n",
      "[101]\ttraining's l1: 0.710044\tvalid_1's l1: 0.721533\n",
      "[102]\ttraining's l1: 0.705767\tvalid_1's l1: 0.717262\n",
      "[103]\ttraining's l1: 0.704206\tvalid_1's l1: 0.715721\n",
      "[104]\ttraining's l1: 0.701495\tvalid_1's l1: 0.712927\n",
      "[105]\ttraining's l1: 0.697649\tvalid_1's l1: 0.709047\n",
      "[106]\ttraining's l1: 0.695281\tvalid_1's l1: 0.70661\n",
      "[107]\ttraining's l1: 0.694158\tvalid_1's l1: 0.705507\n",
      "[108]\ttraining's l1: 0.690619\tvalid_1's l1: 0.702018\n",
      "[109]\ttraining's l1: 0.687121\tvalid_1's l1: 0.698445\n",
      "[110]\ttraining's l1: 0.685112\tvalid_1's l1: 0.696463\n",
      "[111]\ttraining's l1: 0.684314\tvalid_1's l1: 0.695759\n",
      "[112]\ttraining's l1: 0.681838\tvalid_1's l1: 0.693247\n",
      "[113]\ttraining's l1: 0.680902\tvalid_1's l1: 0.692271\n",
      "[114]\ttraining's l1: 0.677665\tvalid_1's l1: 0.689018\n",
      "[115]\ttraining's l1: 0.674732\tvalid_1's l1: 0.686018\n",
      "[116]\ttraining's l1: 0.673151\tvalid_1's l1: 0.684545\n",
      "[117]\ttraining's l1: 0.670613\tvalid_1's l1: 0.681905\n",
      "[118]\ttraining's l1: 0.669658\tvalid_1's l1: 0.68096\n",
      "[119]\ttraining's l1: 0.665131\tvalid_1's l1: 0.676501\n",
      "[120]\ttraining's l1: 0.662013\tvalid_1's l1: 0.673306\n",
      "[121]\ttraining's l1: 0.660456\tvalid_1's l1: 0.671685\n",
      "[122]\ttraining's l1: 0.657381\tvalid_1's l1: 0.668611\n",
      "[123]\ttraining's l1: 0.655794\tvalid_1's l1: 0.667061\n",
      "[124]\ttraining's l1: 0.652378\tvalid_1's l1: 0.663665\n",
      "[125]\ttraining's l1: 0.649807\tvalid_1's l1: 0.661114\n",
      "[126]\ttraining's l1: 0.648753\tvalid_1's l1: 0.660064\n",
      "[127]\ttraining's l1: 0.648042\tvalid_1's l1: 0.659376\n",
      "[128]\ttraining's l1: 0.645474\tvalid_1's l1: 0.656723\n",
      "[129]\ttraining's l1: 0.643969\tvalid_1's l1: 0.655088\n",
      "[130]\ttraining's l1: 0.641729\tvalid_1's l1: 0.652729\n",
      "[131]\ttraining's l1: 0.639822\tvalid_1's l1: 0.650664\n",
      "[132]\ttraining's l1: 0.638887\tvalid_1's l1: 0.649729\n",
      "[133]\ttraining's l1: 0.638075\tvalid_1's l1: 0.648936\n",
      "[134]\ttraining's l1: 0.63622\tvalid_1's l1: 0.64705\n",
      "[135]\ttraining's l1: 0.632964\tvalid_1's l1: 0.643834\n",
      "[136]\ttraining's l1: 0.632041\tvalid_1's l1: 0.642967\n",
      "[137]\ttraining's l1: 0.631524\tvalid_1's l1: 0.642433\n",
      "[138]\ttraining's l1: 0.629065\tvalid_1's l1: 0.639885\n",
      "[139]\ttraining's l1: 0.626972\tvalid_1's l1: 0.637856\n",
      "[140]\ttraining's l1: 0.624365\tvalid_1's l1: 0.635228\n",
      "[141]\ttraining's l1: 0.623294\tvalid_1's l1: 0.634294\n",
      "[142]\ttraining's l1: 0.621404\tvalid_1's l1: 0.632477\n",
      "[143]\ttraining's l1: 0.620984\tvalid_1's l1: 0.632095\n",
      "[144]\ttraining's l1: 0.618909\tvalid_1's l1: 0.629969\n",
      "[145]\ttraining's l1: 0.617104\tvalid_1's l1: 0.628223\n",
      "[146]\ttraining's l1: 0.615606\tvalid_1's l1: 0.626722\n",
      "[147]\ttraining's l1: 0.614416\tvalid_1's l1: 0.625597\n",
      "[148]\ttraining's l1: 0.612636\tvalid_1's l1: 0.62374\n",
      "[149]\ttraining's l1: 0.61086\tvalid_1's l1: 0.621815\n",
      "[150]\ttraining's l1: 0.609947\tvalid_1's l1: 0.620908\n",
      "[151]\ttraining's l1: 0.608458\tvalid_1's l1: 0.619417\n",
      "[152]\ttraining's l1: 0.607363\tvalid_1's l1: 0.618339\n",
      "[153]\ttraining's l1: 0.604844\tvalid_1's l1: 0.615851\n",
      "[154]\ttraining's l1: 0.601654\tvalid_1's l1: 0.612743\n",
      "[155]\ttraining's l1: 0.601274\tvalid_1's l1: 0.612394\n",
      "[156]\ttraining's l1: 0.599169\tvalid_1's l1: 0.610231\n",
      "[157]\ttraining's l1: 0.597936\tvalid_1's l1: 0.609064\n",
      "[158]\ttraining's l1: 0.597483\tvalid_1's l1: 0.608644\n",
      "[159]\ttraining's l1: 0.594762\tvalid_1's l1: 0.605932\n",
      "[160]\ttraining's l1: 0.593016\tvalid_1's l1: 0.604185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[161]\ttraining's l1: 0.59263\tvalid_1's l1: 0.603803\n",
      "[162]\ttraining's l1: 0.59134\tvalid_1's l1: 0.602513\n",
      "[163]\ttraining's l1: 0.588677\tvalid_1's l1: 0.599874\n",
      "[164]\ttraining's l1: 0.587204\tvalid_1's l1: 0.598245\n",
      "[165]\ttraining's l1: 0.585392\tvalid_1's l1: 0.596426\n",
      "[166]\ttraining's l1: 0.584271\tvalid_1's l1: 0.595374\n",
      "[167]\ttraining's l1: 0.583593\tvalid_1's l1: 0.594759\n",
      "[168]\ttraining's l1: 0.58206\tvalid_1's l1: 0.593132\n",
      "[169]\ttraining's l1: 0.580569\tvalid_1's l1: 0.591608\n",
      "[170]\ttraining's l1: 0.579766\tvalid_1's l1: 0.590829\n",
      "[171]\ttraining's l1: 0.57838\tvalid_1's l1: 0.589402\n",
      "[172]\ttraining's l1: 0.575989\tvalid_1's l1: 0.587025\n",
      "[173]\ttraining's l1: 0.575087\tvalid_1's l1: 0.586219\n",
      "[174]\ttraining's l1: 0.574767\tvalid_1's l1: 0.585936\n",
      "[175]\ttraining's l1: 0.573401\tvalid_1's l1: 0.584516\n",
      "[176]\ttraining's l1: 0.571207\tvalid_1's l1: 0.58234\n",
      "[177]\ttraining's l1: 0.570124\tvalid_1's l1: 0.581246\n",
      "[178]\ttraining's l1: 0.567182\tvalid_1's l1: 0.578348\n",
      "[179]\ttraining's l1: 0.565041\tvalid_1's l1: 0.576222\n",
      "[180]\ttraining's l1: 0.564516\tvalid_1's l1: 0.575738\n",
      "[181]\ttraining's l1: 0.563496\tvalid_1's l1: 0.574792\n",
      "[182]\ttraining's l1: 0.562666\tvalid_1's l1: 0.57402\n",
      "[183]\ttraining's l1: 0.561483\tvalid_1's l1: 0.572771\n",
      "[184]\ttraining's l1: 0.558685\tvalid_1's l1: 0.570113\n",
      "[185]\ttraining's l1: 0.557258\tvalid_1's l1: 0.568698\n",
      "[186]\ttraining's l1: 0.556121\tvalid_1's l1: 0.567561\n",
      "[187]\ttraining's l1: 0.554254\tvalid_1's l1: 0.565737\n",
      "[188]\ttraining's l1: 0.553636\tvalid_1's l1: 0.565121\n",
      "[189]\ttraining's l1: 0.552611\tvalid_1's l1: 0.564079\n",
      "[190]\ttraining's l1: 0.551096\tvalid_1's l1: 0.562561\n",
      "[191]\ttraining's l1: 0.55083\tvalid_1's l1: 0.562312\n",
      "[192]\ttraining's l1: 0.550338\tvalid_1's l1: 0.561858\n",
      "[193]\ttraining's l1: 0.549321\tvalid_1's l1: 0.560829\n",
      "[194]\ttraining's l1: 0.548257\tvalid_1's l1: 0.559741\n",
      "[195]\ttraining's l1: 0.547265\tvalid_1's l1: 0.558749\n",
      "[196]\ttraining's l1: 0.546467\tvalid_1's l1: 0.558057\n",
      "[197]\ttraining's l1: 0.54563\tvalid_1's l1: 0.55718\n",
      "[198]\ttraining's l1: 0.545313\tvalid_1's l1: 0.556926\n",
      "[199]\ttraining's l1: 0.54419\tvalid_1's l1: 0.555819\n",
      "[200]\ttraining's l1: 0.543074\tvalid_1's l1: 0.554748\n",
      "[201]\ttraining's l1: 0.542381\tvalid_1's l1: 0.55406\n",
      "[202]\ttraining's l1: 0.541859\tvalid_1's l1: 0.553591\n",
      "[203]\ttraining's l1: 0.541264\tvalid_1's l1: 0.553006\n",
      "[204]\ttraining's l1: 0.540248\tvalid_1's l1: 0.551975\n",
      "[205]\ttraining's l1: 0.539929\tvalid_1's l1: 0.551647\n",
      "[206]\ttraining's l1: 0.537692\tvalid_1's l1: 0.549426\n",
      "[207]\ttraining's l1: 0.536748\tvalid_1's l1: 0.548478\n",
      "[208]\ttraining's l1: 0.536135\tvalid_1's l1: 0.547916\n",
      "[209]\ttraining's l1: 0.535939\tvalid_1's l1: 0.547744\n",
      "[210]\ttraining's l1: 0.534977\tvalid_1's l1: 0.546771\n",
      "[211]\ttraining's l1: 0.532765\tvalid_1's l1: 0.544608\n",
      "[212]\ttraining's l1: 0.530168\tvalid_1's l1: 0.541929\n",
      "[213]\ttraining's l1: 0.529023\tvalid_1's l1: 0.540805\n",
      "[214]\ttraining's l1: 0.527833\tvalid_1's l1: 0.539666\n",
      "[215]\ttraining's l1: 0.526886\tvalid_1's l1: 0.538707\n",
      "[216]\ttraining's l1: 0.526017\tvalid_1's l1: 0.537872\n",
      "[217]\ttraining's l1: 0.525137\tvalid_1's l1: 0.536936\n",
      "[218]\ttraining's l1: 0.524727\tvalid_1's l1: 0.536524\n",
      "[219]\ttraining's l1: 0.522379\tvalid_1's l1: 0.534361\n",
      "[220]\ttraining's l1: 0.521328\tvalid_1's l1: 0.533324\n",
      "[221]\ttraining's l1: 0.520628\tvalid_1's l1: 0.532618\n",
      "[222]\ttraining's l1: 0.519822\tvalid_1's l1: 0.531879\n",
      "[223]\ttraining's l1: 0.519445\tvalid_1's l1: 0.531537\n",
      "[224]\ttraining's l1: 0.5185\tvalid_1's l1: 0.530607\n",
      "[225]\ttraining's l1: 0.517721\tvalid_1's l1: 0.529787\n",
      "[226]\ttraining's l1: 0.515053\tvalid_1's l1: 0.527272\n",
      "[227]\ttraining's l1: 0.514972\tvalid_1's l1: 0.527234\n",
      "[228]\ttraining's l1: 0.513723\tvalid_1's l1: 0.526022\n",
      "[229]\ttraining's l1: 0.512635\tvalid_1's l1: 0.5249\n",
      "[230]\ttraining's l1: 0.509968\tvalid_1's l1: 0.522375\n",
      "[231]\ttraining's l1: 0.508331\tvalid_1's l1: 0.52074\n",
      "[232]\ttraining's l1: 0.507907\tvalid_1's l1: 0.520255\n",
      "[233]\ttraining's l1: 0.506625\tvalid_1's l1: 0.518992\n",
      "[234]\ttraining's l1: 0.504116\tvalid_1's l1: 0.516609\n",
      "[235]\ttraining's l1: 0.504053\tvalid_1's l1: 0.516575\n",
      "[236]\ttraining's l1: 0.503735\tvalid_1's l1: 0.516277\n",
      "[237]\ttraining's l1: 0.501472\tvalid_1's l1: 0.513892\n",
      "[238]\ttraining's l1: 0.500582\tvalid_1's l1: 0.512955\n",
      "[239]\ttraining's l1: 0.499729\tvalid_1's l1: 0.512127\n",
      "[240]\ttraining's l1: 0.498975\tvalid_1's l1: 0.511382\n",
      "[241]\ttraining's l1: 0.498492\tvalid_1's l1: 0.510929\n",
      "[242]\ttraining's l1: 0.498137\tvalid_1's l1: 0.510593\n",
      "[243]\ttraining's l1: 0.495912\tvalid_1's l1: 0.508477\n",
      "[244]\ttraining's l1: 0.494721\tvalid_1's l1: 0.507307\n",
      "[245]\ttraining's l1: 0.494068\tvalid_1's l1: 0.506647\n",
      "[246]\ttraining's l1: 0.493889\tvalid_1's l1: 0.506542\n",
      "[247]\ttraining's l1: 0.493569\tvalid_1's l1: 0.506247\n",
      "[248]\ttraining's l1: 0.491803\tvalid_1's l1: 0.504545\n",
      "[249]\ttraining's l1: 0.490377\tvalid_1's l1: 0.503129\n",
      "[250]\ttraining's l1: 0.489624\tvalid_1's l1: 0.50237\n",
      "[251]\ttraining's l1: 0.489495\tvalid_1's l1: 0.502323\n",
      "[252]\ttraining's l1: 0.48773\tvalid_1's l1: 0.500641\n",
      "[253]\ttraining's l1: 0.48711\tvalid_1's l1: 0.499998\n",
      "[254]\ttraining's l1: 0.486491\tvalid_1's l1: 0.499358\n",
      "[255]\ttraining's l1: 0.484734\tvalid_1's l1: 0.497653\n",
      "[256]\ttraining's l1: 0.483335\tvalid_1's l1: 0.496307\n",
      "[257]\ttraining's l1: 0.481454\tvalid_1's l1: 0.494371\n",
      "[258]\ttraining's l1: 0.481104\tvalid_1's l1: 0.494028\n",
      "[259]\ttraining's l1: 0.48048\tvalid_1's l1: 0.49345\n",
      "[260]\ttraining's l1: 0.479923\tvalid_1's l1: 0.492869\n",
      "[261]\ttraining's l1: 0.478453\tvalid_1's l1: 0.491457\n",
      "[262]\ttraining's l1: 0.478297\tvalid_1's l1: 0.491366\n",
      "[263]\ttraining's l1: 0.477109\tvalid_1's l1: 0.490152\n",
      "[264]\ttraining's l1: 0.476873\tvalid_1's l1: 0.489949\n",
      "[265]\ttraining's l1: 0.476126\tvalid_1's l1: 0.489207\n",
      "[266]\ttraining's l1: 0.475879\tvalid_1's l1: 0.48898\n",
      "[267]\ttraining's l1: 0.475069\tvalid_1's l1: 0.488149\n",
      "[268]\ttraining's l1: 0.473948\tvalid_1's l1: 0.487027\n",
      "[269]\ttraining's l1: 0.473182\tvalid_1's l1: 0.486285\n",
      "[270]\ttraining's l1: 0.471516\tvalid_1's l1: 0.484551\n",
      "[271]\ttraining's l1: 0.469988\tvalid_1's l1: 0.483001\n",
      "[272]\ttraining's l1: 0.469279\tvalid_1's l1: 0.482297\n",
      "[273]\ttraining's l1: 0.468993\tvalid_1's l1: 0.482054\n",
      "[274]\ttraining's l1: 0.466916\tvalid_1's l1: 0.480039\n",
      "[275]\ttraining's l1: 0.465446\tvalid_1's l1: 0.478562\n",
      "[276]\ttraining's l1: 0.465202\tvalid_1's l1: 0.478353\n",
      "[277]\ttraining's l1: 0.464863\tvalid_1's l1: 0.478047\n",
      "[278]\ttraining's l1: 0.464615\tvalid_1's l1: 0.477819\n",
      "[279]\ttraining's l1: 0.464418\tvalid_1's l1: 0.477652\n",
      "[280]\ttraining's l1: 0.463476\tvalid_1's l1: 0.476678\n",
      "[281]\ttraining's l1: 0.462575\tvalid_1's l1: 0.475777\n",
      "[282]\ttraining's l1: 0.461612\tvalid_1's l1: 0.474839\n",
      "[283]\ttraining's l1: 0.460371\tvalid_1's l1: 0.473566\n",
      "[284]\ttraining's l1: 0.458403\tvalid_1's l1: 0.471524\n",
      "[285]\ttraining's l1: 0.457428\tvalid_1's l1: 0.470527\n",
      "[286]\ttraining's l1: 0.455765\tvalid_1's l1: 0.468842\n",
      "[287]\ttraining's l1: 0.455744\tvalid_1's l1: 0.468862\n",
      "[288]\ttraining's l1: 0.45443\tvalid_1's l1: 0.467488\n",
      "[289]\ttraining's l1: 0.453897\tvalid_1's l1: 0.466939\n",
      "[290]\ttraining's l1: 0.451972\tvalid_1's l1: 0.465137\n",
      "[291]\ttraining's l1: 0.451762\tvalid_1's l1: 0.464926\n",
      "[292]\ttraining's l1: 0.450851\tvalid_1's l1: 0.464004\n",
      "[293]\ttraining's l1: 0.450058\tvalid_1's l1: 0.46329\n",
      "[294]\ttraining's l1: 0.448969\tvalid_1's l1: 0.462256\n",
      "[295]\ttraining's l1: 0.449022\tvalid_1's l1: 0.462328\n",
      "[296]\ttraining's l1: 0.447104\tvalid_1's l1: 0.460401\n",
      "[297]\ttraining's l1: 0.446624\tvalid_1's l1: 0.459965\n",
      "[298]\ttraining's l1: 0.445422\tvalid_1's l1: 0.458755\n",
      "[299]\ttraining's l1: 0.443657\tvalid_1's l1: 0.457115\n",
      "[300]\ttraining's l1: 0.443212\tvalid_1's l1: 0.456663\n",
      "[301]\ttraining's l1: 0.443026\tvalid_1's l1: 0.45651\n",
      "[302]\ttraining's l1: 0.441425\tvalid_1's l1: 0.454933\n",
      "[303]\ttraining's l1: 0.44049\tvalid_1's l1: 0.453944\n",
      "[304]\ttraining's l1: 0.439826\tvalid_1's l1: 0.45331\n",
      "[305]\ttraining's l1: 0.439454\tvalid_1's l1: 0.452954\n",
      "[306]\ttraining's l1: 0.438425\tvalid_1's l1: 0.4519\n",
      "[307]\ttraining's l1: 0.436891\tvalid_1's l1: 0.450488\n",
      "[308]\ttraining's l1: 0.436481\tvalid_1's l1: 0.450079\n",
      "[309]\ttraining's l1: 0.436312\tvalid_1's l1: 0.449944\n",
      "[310]\ttraining's l1: 0.434791\tvalid_1's l1: 0.448465\n",
      "[311]\ttraining's l1: 0.434403\tvalid_1's l1: 0.448096\n",
      "[312]\ttraining's l1: 0.433879\tvalid_1's l1: 0.447567\n",
      "[313]\ttraining's l1: 0.432453\tvalid_1's l1: 0.446172\n",
      "[314]\ttraining's l1: 0.431498\tvalid_1's l1: 0.445186\n",
      "[315]\ttraining's l1: 0.430577\tvalid_1's l1: 0.444248\n",
      "[316]\ttraining's l1: 0.430536\tvalid_1's l1: 0.444199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[317]\ttraining's l1: 0.42924\tvalid_1's l1: 0.443001\n",
      "[318]\ttraining's l1: 0.427545\tvalid_1's l1: 0.441381\n",
      "[319]\ttraining's l1: 0.427259\tvalid_1's l1: 0.441119\n",
      "[320]\ttraining's l1: 0.427113\tvalid_1's l1: 0.441023\n",
      "[321]\ttraining's l1: 0.426258\tvalid_1's l1: 0.440142\n",
      "[322]\ttraining's l1: 0.425451\tvalid_1's l1: 0.439329\n",
      "[323]\ttraining's l1: 0.424391\tvalid_1's l1: 0.438227\n",
      "[324]\ttraining's l1: 0.423928\tvalid_1's l1: 0.437755\n",
      "[325]\ttraining's l1: 0.423249\tvalid_1's l1: 0.437075\n",
      "[326]\ttraining's l1: 0.423018\tvalid_1's l1: 0.436848\n",
      "[327]\ttraining's l1: 0.422979\tvalid_1's l1: 0.436793\n",
      "[328]\ttraining's l1: 0.422741\tvalid_1's l1: 0.43657\n",
      "[329]\ttraining's l1: 0.421053\tvalid_1's l1: 0.434851\n",
      "[330]\ttraining's l1: 0.420685\tvalid_1's l1: 0.434447\n",
      "[331]\ttraining's l1: 0.420434\tvalid_1's l1: 0.434182\n",
      "[332]\ttraining's l1: 0.41952\tvalid_1's l1: 0.433234\n",
      "[333]\ttraining's l1: 0.418744\tvalid_1's l1: 0.432443\n",
      "[334]\ttraining's l1: 0.418547\tvalid_1's l1: 0.432276\n",
      "[335]\ttraining's l1: 0.418504\tvalid_1's l1: 0.432269\n",
      "[336]\ttraining's l1: 0.417513\tvalid_1's l1: 0.431355\n",
      "[337]\ttraining's l1: 0.416381\tvalid_1's l1: 0.430275\n",
      "[338]\ttraining's l1: 0.414965\tvalid_1's l1: 0.428942\n",
      "[339]\ttraining's l1: 0.413993\tvalid_1's l1: 0.427991\n",
      "[340]\ttraining's l1: 0.41273\tvalid_1's l1: 0.4268\n",
      "[341]\ttraining's l1: 0.412571\tvalid_1's l1: 0.426675\n",
      "[342]\ttraining's l1: 0.412333\tvalid_1's l1: 0.426474\n",
      "[343]\ttraining's l1: 0.411927\tvalid_1's l1: 0.426044\n",
      "[344]\ttraining's l1: 0.411256\tvalid_1's l1: 0.425364\n",
      "[345]\ttraining's l1: 0.411235\tvalid_1's l1: 0.425365\n",
      "[346]\ttraining's l1: 0.410964\tvalid_1's l1: 0.425086\n",
      "[347]\ttraining's l1: 0.410767\tvalid_1's l1: 0.424921\n",
      "[348]\ttraining's l1: 0.4103\tvalid_1's l1: 0.424455\n",
      "[349]\ttraining's l1: 0.410087\tvalid_1's l1: 0.424265\n",
      "[350]\ttraining's l1: 0.409815\tvalid_1's l1: 0.423963\n",
      "[351]\ttraining's l1: 0.409531\tvalid_1's l1: 0.423695\n",
      "[352]\ttraining's l1: 0.409014\tvalid_1's l1: 0.423207\n",
      "[353]\ttraining's l1: 0.408962\tvalid_1's l1: 0.423165\n",
      "[354]\ttraining's l1: 0.408821\tvalid_1's l1: 0.423045\n",
      "[355]\ttraining's l1: 0.408146\tvalid_1's l1: 0.422329\n",
      "[356]\ttraining's l1: 0.407538\tvalid_1's l1: 0.421725\n",
      "[357]\ttraining's l1: 0.407166\tvalid_1's l1: 0.421386\n",
      "[358]\ttraining's l1: 0.406959\tvalid_1's l1: 0.421224\n",
      "[359]\ttraining's l1: 0.406652\tvalid_1's l1: 0.420961\n",
      "[360]\ttraining's l1: 0.40641\tvalid_1's l1: 0.420733\n",
      "[361]\ttraining's l1: 0.406096\tvalid_1's l1: 0.420424\n",
      "[362]\ttraining's l1: 0.406013\tvalid_1's l1: 0.420354\n",
      "[363]\ttraining's l1: 0.405746\tvalid_1's l1: 0.420118\n",
      "[364]\ttraining's l1: 0.405148\tvalid_1's l1: 0.41952\n",
      "[365]\ttraining's l1: 0.404879\tvalid_1's l1: 0.419257\n",
      "[366]\ttraining's l1: 0.4035\tvalid_1's l1: 0.417904\n",
      "[367]\ttraining's l1: 0.403207\tvalid_1's l1: 0.417641\n",
      "[368]\ttraining's l1: 0.402439\tvalid_1's l1: 0.416856\n",
      "[369]\ttraining's l1: 0.402295\tvalid_1's l1: 0.416713\n",
      "[370]\ttraining's l1: 0.401629\tvalid_1's l1: 0.416025\n",
      "[371]\ttraining's l1: 0.40134\tvalid_1's l1: 0.415751\n",
      "[372]\ttraining's l1: 0.401216\tvalid_1's l1: 0.415582\n",
      "[373]\ttraining's l1: 0.40108\tvalid_1's l1: 0.415434\n",
      "[374]\ttraining's l1: 0.400426\tvalid_1's l1: 0.414795\n",
      "[375]\ttraining's l1: 0.400171\tvalid_1's l1: 0.414534\n",
      "[376]\ttraining's l1: 0.399491\tvalid_1's l1: 0.413835\n",
      "[377]\ttraining's l1: 0.399124\tvalid_1's l1: 0.413432\n",
      "[378]\ttraining's l1: 0.399113\tvalid_1's l1: 0.413447\n",
      "[379]\ttraining's l1: 0.398849\tvalid_1's l1: 0.413157\n",
      "[380]\ttraining's l1: 0.398243\tvalid_1's l1: 0.412559\n",
      "[381]\ttraining's l1: 0.396979\tvalid_1's l1: 0.411308\n",
      "[382]\ttraining's l1: 0.396178\tvalid_1's l1: 0.410515\n",
      "[383]\ttraining's l1: 0.395929\tvalid_1's l1: 0.410283\n",
      "[384]\ttraining's l1: 0.395665\tvalid_1's l1: 0.410024\n",
      "[385]\ttraining's l1: 0.39549\tvalid_1's l1: 0.40988\n",
      "[386]\ttraining's l1: 0.395411\tvalid_1's l1: 0.409782\n",
      "[387]\ttraining's l1: 0.394835\tvalid_1's l1: 0.409214\n",
      "[388]\ttraining's l1: 0.394482\tvalid_1's l1: 0.408872\n",
      "[389]\ttraining's l1: 0.394253\tvalid_1's l1: 0.408647\n",
      "[390]\ttraining's l1: 0.393082\tvalid_1's l1: 0.407521\n",
      "[391]\ttraining's l1: 0.391829\tvalid_1's l1: 0.406231\n",
      "[392]\ttraining's l1: 0.39163\tvalid_1's l1: 0.406031\n",
      "[393]\ttraining's l1: 0.391496\tvalid_1's l1: 0.405923\n",
      "[394]\ttraining's l1: 0.391362\tvalid_1's l1: 0.405741\n",
      "[395]\ttraining's l1: 0.390537\tvalid_1's l1: 0.404948\n",
      "[396]\ttraining's l1: 0.390056\tvalid_1's l1: 0.404426\n",
      "[397]\ttraining's l1: 0.38967\tvalid_1's l1: 0.404097\n",
      "[398]\ttraining's l1: 0.389389\tvalid_1's l1: 0.403817\n",
      "[399]\ttraining's l1: 0.389205\tvalid_1's l1: 0.403646\n",
      "[400]\ttraining's l1: 0.388755\tvalid_1's l1: 0.403164\n",
      "[401]\ttraining's l1: 0.388294\tvalid_1's l1: 0.40269\n",
      "[402]\ttraining's l1: 0.388249\tvalid_1's l1: 0.402673\n",
      "[403]\ttraining's l1: 0.38809\tvalid_1's l1: 0.402529\n",
      "[404]\ttraining's l1: 0.387365\tvalid_1's l1: 0.401797\n",
      "[405]\ttraining's l1: 0.387117\tvalid_1's l1: 0.401537\n",
      "[406]\ttraining's l1: 0.386893\tvalid_1's l1: 0.40138\n",
      "[407]\ttraining's l1: 0.386851\tvalid_1's l1: 0.401319\n",
      "[408]\ttraining's l1: 0.386614\tvalid_1's l1: 0.401101\n",
      "[409]\ttraining's l1: 0.386397\tvalid_1's l1: 0.400867\n",
      "[410]\ttraining's l1: 0.385871\tvalid_1's l1: 0.400347\n",
      "[411]\ttraining's l1: 0.384617\tvalid_1's l1: 0.39907\n",
      "[412]\ttraining's l1: 0.384437\tvalid_1's l1: 0.398899\n",
      "[413]\ttraining's l1: 0.38409\tvalid_1's l1: 0.398578\n",
      "[414]\ttraining's l1: 0.38406\tvalid_1's l1: 0.398571\n",
      "[415]\ttraining's l1: 0.383904\tvalid_1's l1: 0.39843\n",
      "[416]\ttraining's l1: 0.383369\tvalid_1's l1: 0.397909\n",
      "[417]\ttraining's l1: 0.383149\tvalid_1's l1: 0.397755\n",
      "[418]\ttraining's l1: 0.382867\tvalid_1's l1: 0.397488\n",
      "[419]\ttraining's l1: 0.382591\tvalid_1's l1: 0.397212\n",
      "[420]\ttraining's l1: 0.382421\tvalid_1's l1: 0.397058\n",
      "[421]\ttraining's l1: 0.382203\tvalid_1's l1: 0.396861\n",
      "[422]\ttraining's l1: 0.382181\tvalid_1's l1: 0.396843\n",
      "[423]\ttraining's l1: 0.381797\tvalid_1's l1: 0.396467\n",
      "[424]\ttraining's l1: 0.381659\tvalid_1's l1: 0.396343\n",
      "[425]\ttraining's l1: 0.38148\tvalid_1's l1: 0.396157\n",
      "[426]\ttraining's l1: 0.380692\tvalid_1's l1: 0.395385\n",
      "[427]\ttraining's l1: 0.379819\tvalid_1's l1: 0.394576\n",
      "[428]\ttraining's l1: 0.379584\tvalid_1's l1: 0.394366\n",
      "[429]\ttraining's l1: 0.379185\tvalid_1's l1: 0.393992\n",
      "[430]\ttraining's l1: 0.37878\tvalid_1's l1: 0.393558\n",
      "[431]\ttraining's l1: 0.378353\tvalid_1's l1: 0.393123\n",
      "[432]\ttraining's l1: 0.377999\tvalid_1's l1: 0.392798\n",
      "[433]\ttraining's l1: 0.377798\tvalid_1's l1: 0.392591\n",
      "[434]\ttraining's l1: 0.377701\tvalid_1's l1: 0.392573\n",
      "[435]\ttraining's l1: 0.377582\tvalid_1's l1: 0.392466\n",
      "[436]\ttraining's l1: 0.377331\tvalid_1's l1: 0.392235\n",
      "[437]\ttraining's l1: 0.37725\tvalid_1's l1: 0.39217\n",
      "[438]\ttraining's l1: 0.377061\tvalid_1's l1: 0.391991\n",
      "[439]\ttraining's l1: 0.377036\tvalid_1's l1: 0.391943\n",
      "[440]\ttraining's l1: 0.376938\tvalid_1's l1: 0.391855\n",
      "[441]\ttraining's l1: 0.376578\tvalid_1's l1: 0.39151\n",
      "[442]\ttraining's l1: 0.376451\tvalid_1's l1: 0.391362\n",
      "[443]\ttraining's l1: 0.376195\tvalid_1's l1: 0.391068\n",
      "[444]\ttraining's l1: 0.375428\tvalid_1's l1: 0.39036\n",
      "[445]\ttraining's l1: 0.374991\tvalid_1's l1: 0.389886\n",
      "[446]\ttraining's l1: 0.37464\tvalid_1's l1: 0.389526\n",
      "[447]\ttraining's l1: 0.374194\tvalid_1's l1: 0.389131\n",
      "[448]\ttraining's l1: 0.374031\tvalid_1's l1: 0.388984\n",
      "[449]\ttraining's l1: 0.373463\tvalid_1's l1: 0.388497\n",
      "[450]\ttraining's l1: 0.373225\tvalid_1's l1: 0.388273\n",
      "[451]\ttraining's l1: 0.372746\tvalid_1's l1: 0.387763\n",
      "[452]\ttraining's l1: 0.372715\tvalid_1's l1: 0.387716\n",
      "[453]\ttraining's l1: 0.372434\tvalid_1's l1: 0.387474\n",
      "[454]\ttraining's l1: 0.372317\tvalid_1's l1: 0.387391\n",
      "[455]\ttraining's l1: 0.371896\tvalid_1's l1: 0.386969\n",
      "[456]\ttraining's l1: 0.371734\tvalid_1's l1: 0.386816\n",
      "[457]\ttraining's l1: 0.37073\tvalid_1's l1: 0.385874\n",
      "[458]\ttraining's l1: 0.370307\tvalid_1's l1: 0.385439\n",
      "[459]\ttraining's l1: 0.370199\tvalid_1's l1: 0.385338\n",
      "[460]\ttraining's l1: 0.369265\tvalid_1's l1: 0.384463\n",
      "[461]\ttraining's l1: 0.368825\tvalid_1's l1: 0.384032\n",
      "[462]\ttraining's l1: 0.368247\tvalid_1's l1: 0.383439\n",
      "[463]\ttraining's l1: 0.367942\tvalid_1's l1: 0.38315\n",
      "[464]\ttraining's l1: 0.367662\tvalid_1's l1: 0.382908\n",
      "[465]\ttraining's l1: 0.367388\tvalid_1's l1: 0.382658\n",
      "[466]\ttraining's l1: 0.367203\tvalid_1's l1: 0.382509\n",
      "[467]\ttraining's l1: 0.36701\tvalid_1's l1: 0.382334\n",
      "[468]\ttraining's l1: 0.366808\tvalid_1's l1: 0.382189\n",
      "[469]\ttraining's l1: 0.366098\tvalid_1's l1: 0.38144\n",
      "[470]\ttraining's l1: 0.365806\tvalid_1's l1: 0.381172\n",
      "[471]\ttraining's l1: 0.365634\tvalid_1's l1: 0.381021\n",
      "[472]\ttraining's l1: 0.36508\tvalid_1's l1: 0.380434\n",
      "[473]\ttraining's l1: 0.364802\tvalid_1's l1: 0.380163\n",
      "[474]\ttraining's l1: 0.364743\tvalid_1's l1: 0.380113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[475]\ttraining's l1: 0.364553\tvalid_1's l1: 0.379937\n",
      "[476]\ttraining's l1: 0.364027\tvalid_1's l1: 0.379427\n",
      "[477]\ttraining's l1: 0.363936\tvalid_1's l1: 0.37935\n",
      "[478]\ttraining's l1: 0.362974\tvalid_1's l1: 0.378393\n",
      "[479]\ttraining's l1: 0.362807\tvalid_1's l1: 0.378256\n",
      "[480]\ttraining's l1: 0.362704\tvalid_1's l1: 0.378161\n",
      "[481]\ttraining's l1: 0.362549\tvalid_1's l1: 0.378054\n",
      "[482]\ttraining's l1: 0.362291\tvalid_1's l1: 0.37781\n",
      "[483]\ttraining's l1: 0.362225\tvalid_1's l1: 0.377748\n",
      "[484]\ttraining's l1: 0.362122\tvalid_1's l1: 0.377672\n",
      "[485]\ttraining's l1: 0.362044\tvalid_1's l1: 0.377617\n",
      "[486]\ttraining's l1: 0.362005\tvalid_1's l1: 0.377596\n",
      "[487]\ttraining's l1: 0.361897\tvalid_1's l1: 0.377497\n",
      "[488]\ttraining's l1: 0.361739\tvalid_1's l1: 0.377371\n",
      "[489]\ttraining's l1: 0.360766\tvalid_1's l1: 0.376396\n",
      "[490]\ttraining's l1: 0.36059\tvalid_1's l1: 0.376259\n",
      "[491]\ttraining's l1: 0.360447\tvalid_1's l1: 0.376157\n",
      "[492]\ttraining's l1: 0.360189\tvalid_1's l1: 0.375942\n",
      "[493]\ttraining's l1: 0.359243\tvalid_1's l1: 0.375058\n",
      "[494]\ttraining's l1: 0.359035\tvalid_1's l1: 0.374878\n",
      "[495]\ttraining's l1: 0.358074\tvalid_1's l1: 0.373947\n",
      "[496]\ttraining's l1: 0.357908\tvalid_1's l1: 0.373814\n",
      "[497]\ttraining's l1: 0.357059\tvalid_1's l1: 0.373006\n",
      "[498]\ttraining's l1: 0.357036\tvalid_1's l1: 0.373006\n",
      "[499]\ttraining's l1: 0.35649\tvalid_1's l1: 0.37249\n",
      "[500]\ttraining's l1: 0.356422\tvalid_1's l1: 0.372457\n",
      "[501]\ttraining's l1: 0.356261\tvalid_1's l1: 0.372297\n",
      "[502]\ttraining's l1: 0.355561\tvalid_1's l1: 0.371644\n",
      "[503]\ttraining's l1: 0.355472\tvalid_1's l1: 0.371568\n",
      "[504]\ttraining's l1: 0.354831\tvalid_1's l1: 0.370926\n",
      "[505]\ttraining's l1: 0.354606\tvalid_1's l1: 0.37072\n",
      "[506]\ttraining's l1: 0.354587\tvalid_1's l1: 0.37073\n",
      "[507]\ttraining's l1: 0.354429\tvalid_1's l1: 0.370594\n",
      "[508]\ttraining's l1: 0.354134\tvalid_1's l1: 0.370293\n",
      "[509]\ttraining's l1: 0.353458\tvalid_1's l1: 0.369619\n",
      "[510]\ttraining's l1: 0.353252\tvalid_1's l1: 0.369422\n",
      "[511]\ttraining's l1: 0.353212\tvalid_1's l1: 0.369387\n",
      "[512]\ttraining's l1: 0.352397\tvalid_1's l1: 0.368583\n",
      "[513]\ttraining's l1: 0.352074\tvalid_1's l1: 0.368241\n",
      "[514]\ttraining's l1: 0.35194\tvalid_1's l1: 0.368129\n",
      "[515]\ttraining's l1: 0.351562\tvalid_1's l1: 0.36776\n",
      "[516]\ttraining's l1: 0.351555\tvalid_1's l1: 0.367772\n",
      "[517]\ttraining's l1: 0.351486\tvalid_1's l1: 0.3677\n",
      "[518]\ttraining's l1: 0.351428\tvalid_1's l1: 0.367639\n",
      "[519]\ttraining's l1: 0.351042\tvalid_1's l1: 0.367255\n",
      "[520]\ttraining's l1: 0.351013\tvalid_1's l1: 0.367227\n",
      "[521]\ttraining's l1: 0.35095\tvalid_1's l1: 0.367174\n",
      "[522]\ttraining's l1: 0.35088\tvalid_1's l1: 0.367096\n",
      "[523]\ttraining's l1: 0.350145\tvalid_1's l1: 0.366383\n",
      "[524]\ttraining's l1: 0.349958\tvalid_1's l1: 0.366235\n",
      "[525]\ttraining's l1: 0.349682\tvalid_1's l1: 0.365984\n",
      "[526]\ttraining's l1: 0.34958\tvalid_1's l1: 0.365905\n",
      "[527]\ttraining's l1: 0.349447\tvalid_1's l1: 0.365815\n",
      "[528]\ttraining's l1: 0.349173\tvalid_1's l1: 0.365548\n",
      "[529]\ttraining's l1: 0.348558\tvalid_1's l1: 0.364946\n",
      "[530]\ttraining's l1: 0.348167\tvalid_1's l1: 0.364573\n",
      "[531]\ttraining's l1: 0.347595\tvalid_1's l1: 0.364003\n",
      "[532]\ttraining's l1: 0.347432\tvalid_1's l1: 0.36387\n",
      "[533]\ttraining's l1: 0.34736\tvalid_1's l1: 0.363824\n",
      "[534]\ttraining's l1: 0.347229\tvalid_1's l1: 0.363693\n",
      "[535]\ttraining's l1: 0.346856\tvalid_1's l1: 0.363344\n",
      "[536]\ttraining's l1: 0.346447\tvalid_1's l1: 0.362931\n",
      "[537]\ttraining's l1: 0.34633\tvalid_1's l1: 0.362828\n",
      "[538]\ttraining's l1: 0.346195\tvalid_1's l1: 0.362652\n",
      "[539]\ttraining's l1: 0.346165\tvalid_1's l1: 0.362644\n",
      "[540]\ttraining's l1: 0.34612\tvalid_1's l1: 0.362617\n",
      "[541]\ttraining's l1: 0.345898\tvalid_1's l1: 0.362411\n",
      "[542]\ttraining's l1: 0.345667\tvalid_1's l1: 0.362165\n",
      "[543]\ttraining's l1: 0.345313\tvalid_1's l1: 0.361823\n",
      "[544]\ttraining's l1: 0.345018\tvalid_1's l1: 0.361526\n",
      "[545]\ttraining's l1: 0.34496\tvalid_1's l1: 0.361506\n",
      "[546]\ttraining's l1: 0.344656\tvalid_1's l1: 0.361207\n",
      "[547]\ttraining's l1: 0.344481\tvalid_1's l1: 0.361036\n",
      "[548]\ttraining's l1: 0.34438\tvalid_1's l1: 0.360936\n",
      "[549]\ttraining's l1: 0.343775\tvalid_1's l1: 0.360362\n",
      "[550]\ttraining's l1: 0.343606\tvalid_1's l1: 0.360195\n",
      "[551]\ttraining's l1: 0.343555\tvalid_1's l1: 0.360183\n",
      "[552]\ttraining's l1: 0.343056\tvalid_1's l1: 0.359739\n",
      "[553]\ttraining's l1: 0.342859\tvalid_1's l1: 0.359559\n",
      "[554]\ttraining's l1: 0.34281\tvalid_1's l1: 0.359553\n",
      "[555]\ttraining's l1: 0.342728\tvalid_1's l1: 0.359482\n",
      "[556]\ttraining's l1: 0.341826\tvalid_1's l1: 0.358626\n",
      "[557]\ttraining's l1: 0.341615\tvalid_1's l1: 0.358396\n",
      "[558]\ttraining's l1: 0.341192\tvalid_1's l1: 0.357949\n",
      "[559]\ttraining's l1: 0.341155\tvalid_1's l1: 0.357921\n",
      "[560]\ttraining's l1: 0.341075\tvalid_1's l1: 0.35785\n",
      "[561]\ttraining's l1: 0.341009\tvalid_1's l1: 0.357775\n",
      "[562]\ttraining's l1: 0.340944\tvalid_1's l1: 0.357709\n",
      "[563]\ttraining's l1: 0.340127\tvalid_1's l1: 0.356965\n",
      "[564]\ttraining's l1: 0.340104\tvalid_1's l1: 0.356956\n",
      "[565]\ttraining's l1: 0.339758\tvalid_1's l1: 0.356643\n",
      "[566]\ttraining's l1: 0.339678\tvalid_1's l1: 0.356581\n",
      "[567]\ttraining's l1: 0.33915\tvalid_1's l1: 0.356138\n",
      "[568]\ttraining's l1: 0.338962\tvalid_1's l1: 0.355931\n",
      "[569]\ttraining's l1: 0.33873\tvalid_1's l1: 0.3557\n",
      "[570]\ttraining's l1: 0.338682\tvalid_1's l1: 0.355653\n",
      "[571]\ttraining's l1: 0.338317\tvalid_1's l1: 0.355332\n",
      "[572]\ttraining's l1: 0.338011\tvalid_1's l1: 0.355058\n",
      "[573]\ttraining's l1: 0.337846\tvalid_1's l1: 0.354884\n",
      "[574]\ttraining's l1: 0.33773\tvalid_1's l1: 0.354796\n",
      "[575]\ttraining's l1: 0.337176\tvalid_1's l1: 0.354287\n",
      "[576]\ttraining's l1: 0.337105\tvalid_1's l1: 0.354232\n",
      "[577]\ttraining's l1: 0.336959\tvalid_1's l1: 0.354094\n",
      "[578]\ttraining's l1: 0.336867\tvalid_1's l1: 0.35399\n",
      "[579]\ttraining's l1: 0.336445\tvalid_1's l1: 0.353573\n",
      "[580]\ttraining's l1: 0.336223\tvalid_1's l1: 0.353364\n",
      "[581]\ttraining's l1: 0.336117\tvalid_1's l1: 0.353316\n",
      "[582]\ttraining's l1: 0.335658\tvalid_1's l1: 0.352861\n",
      "[583]\ttraining's l1: 0.33541\tvalid_1's l1: 0.352614\n",
      "[584]\ttraining's l1: 0.334963\tvalid_1's l1: 0.352177\n",
      "[585]\ttraining's l1: 0.334777\tvalid_1's l1: 0.351991\n",
      "[586]\ttraining's l1: 0.33477\tvalid_1's l1: 0.352008\n",
      "[587]\ttraining's l1: 0.334556\tvalid_1's l1: 0.351795\n",
      "[588]\ttraining's l1: 0.334362\tvalid_1's l1: 0.351609\n",
      "[589]\ttraining's l1: 0.334159\tvalid_1's l1: 0.351415\n",
      "[590]\ttraining's l1: 0.334161\tvalid_1's l1: 0.351434\n",
      "[591]\ttraining's l1: 0.334028\tvalid_1's l1: 0.351312\n",
      "[592]\ttraining's l1: 0.333801\tvalid_1's l1: 0.351081\n",
      "[593]\ttraining's l1: 0.333734\tvalid_1's l1: 0.351046\n",
      "[594]\ttraining's l1: 0.3334\tvalid_1's l1: 0.350718\n",
      "[595]\ttraining's l1: 0.332982\tvalid_1's l1: 0.350297\n",
      "[596]\ttraining's l1: 0.332711\tvalid_1's l1: 0.350081\n",
      "[597]\ttraining's l1: 0.332539\tvalid_1's l1: 0.349914\n",
      "[598]\ttraining's l1: 0.332521\tvalid_1's l1: 0.349897\n",
      "[599]\ttraining's l1: 0.332451\tvalid_1's l1: 0.349865\n",
      "[600]\ttraining's l1: 0.332427\tvalid_1's l1: 0.349867\n",
      "[601]\ttraining's l1: 0.332159\tvalid_1's l1: 0.349606\n",
      "[602]\ttraining's l1: 0.331826\tvalid_1's l1: 0.349273\n",
      "[603]\ttraining's l1: 0.331671\tvalid_1's l1: 0.349126\n",
      "[604]\ttraining's l1: 0.331185\tvalid_1's l1: 0.348724\n",
      "[605]\ttraining's l1: 0.330616\tvalid_1's l1: 0.348195\n",
      "[606]\ttraining's l1: 0.33045\tvalid_1's l1: 0.348049\n",
      "[607]\ttraining's l1: 0.330444\tvalid_1's l1: 0.348042\n",
      "[608]\ttraining's l1: 0.330296\tvalid_1's l1: 0.34792\n",
      "[609]\ttraining's l1: 0.330199\tvalid_1's l1: 0.347835\n",
      "[610]\ttraining's l1: 0.330145\tvalid_1's l1: 0.347809\n",
      "[611]\ttraining's l1: 0.329936\tvalid_1's l1: 0.347598\n",
      "[612]\ttraining's l1: 0.329747\tvalid_1's l1: 0.347412\n",
      "[613]\ttraining's l1: 0.329707\tvalid_1's l1: 0.34738\n",
      "[614]\ttraining's l1: 0.329506\tvalid_1's l1: 0.347188\n",
      "[615]\ttraining's l1: 0.329448\tvalid_1's l1: 0.347158\n",
      "[616]\ttraining's l1: 0.329195\tvalid_1's l1: 0.346916\n",
      "[617]\ttraining's l1: 0.328692\tvalid_1's l1: 0.346447\n",
      "[618]\ttraining's l1: 0.328535\tvalid_1's l1: 0.346318\n",
      "[619]\ttraining's l1: 0.328463\tvalid_1's l1: 0.346265\n",
      "[620]\ttraining's l1: 0.328268\tvalid_1's l1: 0.346079\n",
      "[621]\ttraining's l1: 0.328206\tvalid_1's l1: 0.346048\n",
      "[622]\ttraining's l1: 0.327711\tvalid_1's l1: 0.345581\n",
      "[623]\ttraining's l1: 0.327486\tvalid_1's l1: 0.34538\n",
      "[624]\ttraining's l1: 0.327331\tvalid_1's l1: 0.345236\n",
      "[625]\ttraining's l1: 0.327257\tvalid_1's l1: 0.3452\n",
      "[626]\ttraining's l1: 0.326702\tvalid_1's l1: 0.344675\n",
      "[627]\ttraining's l1: 0.326632\tvalid_1's l1: 0.344615\n",
      "[628]\ttraining's l1: 0.326528\tvalid_1's l1: 0.344525\n",
      "[629]\ttraining's l1: 0.326001\tvalid_1's l1: 0.344011\n",
      "[630]\ttraining's l1: 0.325861\tvalid_1's l1: 0.343873\n",
      "[631]\ttraining's l1: 0.325508\tvalid_1's l1: 0.343528\n",
      "[632]\ttraining's l1: 0.325051\tvalid_1's l1: 0.34306\n",
      "[633]\ttraining's l1: 0.324869\tvalid_1's l1: 0.342884\n",
      "[634]\ttraining's l1: 0.324799\tvalid_1's l1: 0.342843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[635]\ttraining's l1: 0.324774\tvalid_1's l1: 0.342823\n",
      "[636]\ttraining's l1: 0.324636\tvalid_1's l1: 0.342701\n",
      "[637]\ttraining's l1: 0.324567\tvalid_1's l1: 0.342608\n",
      "[638]\ttraining's l1: 0.324144\tvalid_1's l1: 0.342206\n",
      "[639]\ttraining's l1: 0.324116\tvalid_1's l1: 0.342165\n",
      "[640]\ttraining's l1: 0.323799\tvalid_1's l1: 0.341866\n",
      "[641]\ttraining's l1: 0.32345\tvalid_1's l1: 0.341487\n",
      "[642]\ttraining's l1: 0.323021\tvalid_1's l1: 0.34107\n",
      "[643]\ttraining's l1: 0.322831\tvalid_1's l1: 0.340875\n",
      "[644]\ttraining's l1: 0.32238\tvalid_1's l1: 0.340432\n",
      "[645]\ttraining's l1: 0.322285\tvalid_1's l1: 0.340361\n",
      "[646]\ttraining's l1: 0.321889\tvalid_1's l1: 0.339958\n",
      "[647]\ttraining's l1: 0.321756\tvalid_1's l1: 0.339833\n",
      "[648]\ttraining's l1: 0.321241\tvalid_1's l1: 0.339359\n",
      "[649]\ttraining's l1: 0.321148\tvalid_1's l1: 0.339304\n",
      "[650]\ttraining's l1: 0.320788\tvalid_1's l1: 0.338908\n",
      "[651]\ttraining's l1: 0.32069\tvalid_1's l1: 0.338821\n",
      "[652]\ttraining's l1: 0.320205\tvalid_1's l1: 0.338384\n",
      "[653]\ttraining's l1: 0.320087\tvalid_1's l1: 0.338306\n",
      "[654]\ttraining's l1: 0.320044\tvalid_1's l1: 0.338292\n",
      "[655]\ttraining's l1: 0.319572\tvalid_1's l1: 0.337874\n",
      "[656]\ttraining's l1: 0.31917\tvalid_1's l1: 0.337476\n",
      "[657]\ttraining's l1: 0.319145\tvalid_1's l1: 0.337477\n",
      "[658]\ttraining's l1: 0.318986\tvalid_1's l1: 0.337319\n",
      "[659]\ttraining's l1: 0.318491\tvalid_1's l1: 0.336835\n",
      "[660]\ttraining's l1: 0.31829\tvalid_1's l1: 0.336644\n",
      "[661]\ttraining's l1: 0.317926\tvalid_1's l1: 0.336283\n",
      "[662]\ttraining's l1: 0.317886\tvalid_1's l1: 0.336275\n",
      "[663]\ttraining's l1: 0.317699\tvalid_1's l1: 0.336087\n",
      "[664]\ttraining's l1: 0.317459\tvalid_1's l1: 0.335877\n",
      "[665]\ttraining's l1: 0.317218\tvalid_1's l1: 0.335626\n",
      "[666]\ttraining's l1: 0.317177\tvalid_1's l1: 0.335624\n",
      "[667]\ttraining's l1: 0.317003\tvalid_1's l1: 0.335447\n",
      "[668]\ttraining's l1: 0.316824\tvalid_1's l1: 0.335287\n",
      "[669]\ttraining's l1: 0.316678\tvalid_1's l1: 0.335161\n",
      "[670]\ttraining's l1: 0.316537\tvalid_1's l1: 0.33503\n",
      "[671]\ttraining's l1: 0.316482\tvalid_1's l1: 0.334968\n",
      "[672]\ttraining's l1: 0.316423\tvalid_1's l1: 0.334921\n",
      "[673]\ttraining's l1: 0.315996\tvalid_1's l1: 0.334502\n",
      "[674]\ttraining's l1: 0.315958\tvalid_1's l1: 0.334476\n",
      "[675]\ttraining's l1: 0.315894\tvalid_1's l1: 0.334424\n",
      "[676]\ttraining's l1: 0.315721\tvalid_1's l1: 0.33425\n",
      "[677]\ttraining's l1: 0.315653\tvalid_1's l1: 0.33418\n",
      "[678]\ttraining's l1: 0.315619\tvalid_1's l1: 0.334175\n",
      "[679]\ttraining's l1: 0.315532\tvalid_1's l1: 0.334099\n",
      "[680]\ttraining's l1: 0.315068\tvalid_1's l1: 0.333671\n",
      "[681]\ttraining's l1: 0.314851\tvalid_1's l1: 0.333454\n",
      "[682]\ttraining's l1: 0.314751\tvalid_1's l1: 0.333369\n",
      "[683]\ttraining's l1: 0.314515\tvalid_1's l1: 0.333153\n",
      "[684]\ttraining's l1: 0.3144\tvalid_1's l1: 0.33305\n",
      "[685]\ttraining's l1: 0.314206\tvalid_1's l1: 0.332851\n",
      "[686]\ttraining's l1: 0.313958\tvalid_1's l1: 0.332607\n",
      "[687]\ttraining's l1: 0.313921\tvalid_1's l1: 0.332591\n",
      "[688]\ttraining's l1: 0.313897\tvalid_1's l1: 0.332573\n",
      "[689]\ttraining's l1: 0.31373\tvalid_1's l1: 0.332413\n",
      "[690]\ttraining's l1: 0.313656\tvalid_1's l1: 0.332361\n",
      "[691]\ttraining's l1: 0.313287\tvalid_1's l1: 0.332022\n",
      "[692]\ttraining's l1: 0.313218\tvalid_1's l1: 0.331939\n",
      "[693]\ttraining's l1: 0.313073\tvalid_1's l1: 0.33181\n",
      "[694]\ttraining's l1: 0.312902\tvalid_1's l1: 0.331658\n",
      "[695]\ttraining's l1: 0.312696\tvalid_1's l1: 0.331443\n",
      "[696]\ttraining's l1: 0.31231\tvalid_1's l1: 0.331077\n",
      "[697]\ttraining's l1: 0.311996\tvalid_1's l1: 0.330763\n",
      "[698]\ttraining's l1: 0.311725\tvalid_1's l1: 0.330509\n",
      "[699]\ttraining's l1: 0.311651\tvalid_1's l1: 0.330447\n",
      "[700]\ttraining's l1: 0.311504\tvalid_1's l1: 0.330304\n",
      "[701]\ttraining's l1: 0.311116\tvalid_1's l1: 0.329933\n",
      "[702]\ttraining's l1: 0.3111\tvalid_1's l1: 0.329946\n",
      "[703]\ttraining's l1: 0.310928\tvalid_1's l1: 0.32977\n",
      "[704]\ttraining's l1: 0.310586\tvalid_1's l1: 0.329441\n",
      "[705]\ttraining's l1: 0.31045\tvalid_1's l1: 0.329324\n",
      "[706]\ttraining's l1: 0.310299\tvalid_1's l1: 0.329189\n",
      "[707]\ttraining's l1: 0.309983\tvalid_1's l1: 0.328896\n",
      "[708]\ttraining's l1: 0.309799\tvalid_1's l1: 0.328707\n",
      "[709]\ttraining's l1: 0.309746\tvalid_1's l1: 0.328647\n",
      "[710]\ttraining's l1: 0.309395\tvalid_1's l1: 0.328294\n",
      "[711]\ttraining's l1: 0.309076\tvalid_1's l1: 0.327982\n",
      "[712]\ttraining's l1: 0.308866\tvalid_1's l1: 0.327783\n",
      "[713]\ttraining's l1: 0.308508\tvalid_1's l1: 0.32744\n",
      "[714]\ttraining's l1: 0.308228\tvalid_1's l1: 0.327173\n",
      "[715]\ttraining's l1: 0.307945\tvalid_1's l1: 0.326909\n",
      "[716]\ttraining's l1: 0.307673\tvalid_1's l1: 0.32665\n",
      "[717]\ttraining's l1: 0.307616\tvalid_1's l1: 0.32663\n",
      "[718]\ttraining's l1: 0.307358\tvalid_1's l1: 0.32639\n",
      "[719]\ttraining's l1: 0.307265\tvalid_1's l1: 0.326316\n",
      "[720]\ttraining's l1: 0.307002\tvalid_1's l1: 0.326074\n",
      "[721]\ttraining's l1: 0.306544\tvalid_1's l1: 0.325613\n",
      "[722]\ttraining's l1: 0.306452\tvalid_1's l1: 0.325519\n",
      "[723]\ttraining's l1: 0.306351\tvalid_1's l1: 0.325434\n",
      "[724]\ttraining's l1: 0.306279\tvalid_1's l1: 0.325371\n",
      "[725]\ttraining's l1: 0.305883\tvalid_1's l1: 0.324964\n",
      "[726]\ttraining's l1: 0.305785\tvalid_1's l1: 0.324878\n",
      "[727]\ttraining's l1: 0.305488\tvalid_1's l1: 0.324596\n",
      "[728]\ttraining's l1: 0.30521\tvalid_1's l1: 0.32435\n",
      "[729]\ttraining's l1: 0.304979\tvalid_1's l1: 0.324122\n",
      "[730]\ttraining's l1: 0.304942\tvalid_1's l1: 0.324076\n",
      "[731]\ttraining's l1: 0.304897\tvalid_1's l1: 0.324054\n",
      "[732]\ttraining's l1: 0.30447\tvalid_1's l1: 0.323644\n",
      "[733]\ttraining's l1: 0.304204\tvalid_1's l1: 0.323402\n",
      "[734]\ttraining's l1: 0.303891\tvalid_1's l1: 0.323098\n",
      "[735]\ttraining's l1: 0.303699\tvalid_1's l1: 0.322902\n",
      "[736]\ttraining's l1: 0.303642\tvalid_1's l1: 0.322874\n",
      "[737]\ttraining's l1: 0.303552\tvalid_1's l1: 0.322785\n",
      "[738]\ttraining's l1: 0.303251\tvalid_1's l1: 0.32249\n",
      "[739]\ttraining's l1: 0.302999\tvalid_1's l1: 0.322254\n",
      "[740]\ttraining's l1: 0.302835\tvalid_1's l1: 0.322108\n",
      "[741]\ttraining's l1: 0.302759\tvalid_1's l1: 0.322047\n",
      "[742]\ttraining's l1: 0.302469\tvalid_1's l1: 0.321773\n",
      "[743]\ttraining's l1: 0.302312\tvalid_1's l1: 0.321654\n",
      "[744]\ttraining's l1: 0.302232\tvalid_1's l1: 0.321594\n",
      "[745]\ttraining's l1: 0.302164\tvalid_1's l1: 0.32152\n",
      "[746]\ttraining's l1: 0.301931\tvalid_1's l1: 0.321301\n",
      "[747]\ttraining's l1: 0.301724\tvalid_1's l1: 0.321106\n",
      "[748]\ttraining's l1: 0.301414\tvalid_1's l1: 0.320815\n",
      "[749]\ttraining's l1: 0.301234\tvalid_1's l1: 0.320653\n",
      "[750]\ttraining's l1: 0.301157\tvalid_1's l1: 0.320587\n",
      "[751]\ttraining's l1: 0.301001\tvalid_1's l1: 0.320454\n",
      "[752]\ttraining's l1: 0.300764\tvalid_1's l1: 0.320237\n",
      "[753]\ttraining's l1: 0.300532\tvalid_1's l1: 0.320019\n",
      "[754]\ttraining's l1: 0.300436\tvalid_1's l1: 0.319946\n",
      "[755]\ttraining's l1: 0.300023\tvalid_1's l1: 0.319531\n",
      "[756]\ttraining's l1: 0.299606\tvalid_1's l1: 0.319138\n",
      "[757]\ttraining's l1: 0.299331\tvalid_1's l1: 0.318879\n",
      "[758]\ttraining's l1: 0.299118\tvalid_1's l1: 0.318691\n",
      "[759]\ttraining's l1: 0.298877\tvalid_1's l1: 0.318485\n",
      "[760]\ttraining's l1: 0.298773\tvalid_1's l1: 0.318396\n",
      "[761]\ttraining's l1: 0.298456\tvalid_1's l1: 0.31809\n",
      "[762]\ttraining's l1: 0.298234\tvalid_1's l1: 0.317882\n",
      "[763]\ttraining's l1: 0.297909\tvalid_1's l1: 0.317572\n",
      "[764]\ttraining's l1: 0.29786\tvalid_1's l1: 0.317532\n",
      "[765]\ttraining's l1: 0.297673\tvalid_1's l1: 0.317367\n",
      "[766]\ttraining's l1: 0.297567\tvalid_1's l1: 0.317276\n",
      "[767]\ttraining's l1: 0.297301\tvalid_1's l1: 0.31706\n",
      "[768]\ttraining's l1: 0.2971\tvalid_1's l1: 0.316874\n",
      "[769]\ttraining's l1: 0.297017\tvalid_1's l1: 0.316789\n",
      "[770]\ttraining's l1: 0.296773\tvalid_1's l1: 0.316567\n",
      "[771]\ttraining's l1: 0.296741\tvalid_1's l1: 0.316545\n",
      "[772]\ttraining's l1: 0.296533\tvalid_1's l1: 0.316341\n",
      "[773]\ttraining's l1: 0.296468\tvalid_1's l1: 0.3163\n",
      "[774]\ttraining's l1: 0.296235\tvalid_1's l1: 0.316066\n",
      "[775]\ttraining's l1: 0.296121\tvalid_1's l1: 0.315976\n",
      "[776]\ttraining's l1: 0.296079\tvalid_1's l1: 0.315948\n",
      "[777]\ttraining's l1: 0.296047\tvalid_1's l1: 0.315915\n",
      "[778]\ttraining's l1: 0.296006\tvalid_1's l1: 0.315878\n",
      "[779]\ttraining's l1: 0.295893\tvalid_1's l1: 0.31576\n",
      "[780]\ttraining's l1: 0.295716\tvalid_1's l1: 0.315598\n",
      "[781]\ttraining's l1: 0.295684\tvalid_1's l1: 0.315569\n",
      "[782]\ttraining's l1: 0.295482\tvalid_1's l1: 0.315374\n",
      "[783]\ttraining's l1: 0.295382\tvalid_1's l1: 0.315283\n",
      "[784]\ttraining's l1: 0.295326\tvalid_1's l1: 0.315271\n",
      "[785]\ttraining's l1: 0.295034\tvalid_1's l1: 0.315\n",
      "[786]\ttraining's l1: 0.295016\tvalid_1's l1: 0.314999\n",
      "[787]\ttraining's l1: 0.294931\tvalid_1's l1: 0.314937\n",
      "[788]\ttraining's l1: 0.294832\tvalid_1's l1: 0.314835\n",
      "[789]\ttraining's l1: 0.294721\tvalid_1's l1: 0.31474\n",
      "[790]\ttraining's l1: 0.294505\tvalid_1's l1: 0.314528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[791]\ttraining's l1: 0.294269\tvalid_1's l1: 0.314298\n",
      "[792]\ttraining's l1: 0.294114\tvalid_1's l1: 0.314152\n",
      "[793]\ttraining's l1: 0.294043\tvalid_1's l1: 0.314084\n",
      "[794]\ttraining's l1: 0.294011\tvalid_1's l1: 0.314062\n",
      "[795]\ttraining's l1: 0.293885\tvalid_1's l1: 0.31394\n",
      "[796]\ttraining's l1: 0.293864\tvalid_1's l1: 0.313948\n",
      "[797]\ttraining's l1: 0.293792\tvalid_1's l1: 0.313959\n",
      "[798]\ttraining's l1: 0.293567\tvalid_1's l1: 0.313746\n",
      "[799]\ttraining's l1: 0.29314\tvalid_1's l1: 0.313359\n",
      "[800]\ttraining's l1: 0.2931\tvalid_1's l1: 0.313341\n",
      "[801]\ttraining's l1: 0.293074\tvalid_1's l1: 0.313317\n",
      "[802]\ttraining's l1: 0.292907\tvalid_1's l1: 0.313157\n",
      "[803]\ttraining's l1: 0.292716\tvalid_1's l1: 0.312984\n",
      "[804]\ttraining's l1: 0.292596\tvalid_1's l1: 0.312869\n",
      "[805]\ttraining's l1: 0.292421\tvalid_1's l1: 0.312699\n",
      "[806]\ttraining's l1: 0.292357\tvalid_1's l1: 0.312653\n",
      "[807]\ttraining's l1: 0.292164\tvalid_1's l1: 0.312447\n",
      "[808]\ttraining's l1: 0.292139\tvalid_1's l1: 0.31243\n",
      "[809]\ttraining's l1: 0.291804\tvalid_1's l1: 0.31207\n",
      "[810]\ttraining's l1: 0.291759\tvalid_1's l1: 0.312029\n",
      "[811]\ttraining's l1: 0.291535\tvalid_1's l1: 0.311794\n",
      "[812]\ttraining's l1: 0.291208\tvalid_1's l1: 0.311451\n",
      "[813]\ttraining's l1: 0.29119\tvalid_1's l1: 0.311447\n",
      "[814]\ttraining's l1: 0.291103\tvalid_1's l1: 0.311364\n",
      "[815]\ttraining's l1: 0.291067\tvalid_1's l1: 0.311359\n",
      "[816]\ttraining's l1: 0.291042\tvalid_1's l1: 0.31134\n",
      "[817]\ttraining's l1: 0.290885\tvalid_1's l1: 0.311187\n",
      "[818]\ttraining's l1: 0.290867\tvalid_1's l1: 0.311183\n",
      "[819]\ttraining's l1: 0.290807\tvalid_1's l1: 0.311127\n",
      "[820]\ttraining's l1: 0.290717\tvalid_1's l1: 0.311044\n",
      "[821]\ttraining's l1: 0.290679\tvalid_1's l1: 0.311009\n",
      "[822]\ttraining's l1: 0.290633\tvalid_1's l1: 0.310977\n",
      "[823]\ttraining's l1: 0.29058\tvalid_1's l1: 0.310929\n",
      "[824]\ttraining's l1: 0.290546\tvalid_1's l1: 0.31091\n",
      "[825]\ttraining's l1: 0.2904\tvalid_1's l1: 0.310772\n",
      "[826]\ttraining's l1: 0.290387\tvalid_1's l1: 0.310777\n",
      "[827]\ttraining's l1: 0.290325\tvalid_1's l1: 0.31072\n",
      "[828]\ttraining's l1: 0.290311\tvalid_1's l1: 0.310725\n",
      "[829]\ttraining's l1: 0.29016\tvalid_1's l1: 0.310578\n",
      "[830]\ttraining's l1: 0.290121\tvalid_1's l1: 0.31056\n",
      "[831]\ttraining's l1: 0.290059\tvalid_1's l1: 0.310517\n",
      "[832]\ttraining's l1: 0.289849\tvalid_1's l1: 0.310311\n",
      "[833]\ttraining's l1: 0.289542\tvalid_1's l1: 0.310018\n",
      "[834]\ttraining's l1: 0.28941\tvalid_1's l1: 0.309867\n",
      "[835]\ttraining's l1: 0.289314\tvalid_1's l1: 0.30978\n",
      "[836]\ttraining's l1: 0.289292\tvalid_1's l1: 0.309766\n",
      "[837]\ttraining's l1: 0.28913\tvalid_1's l1: 0.309622\n",
      "[838]\ttraining's l1: 0.289088\tvalid_1's l1: 0.309626\n",
      "[839]\ttraining's l1: 0.289024\tvalid_1's l1: 0.309565\n",
      "[840]\ttraining's l1: 0.288832\tvalid_1's l1: 0.309393\n",
      "[841]\ttraining's l1: 0.2887\tvalid_1's l1: 0.309264\n",
      "[842]\ttraining's l1: 0.28847\tvalid_1's l1: 0.309045\n",
      "[843]\ttraining's l1: 0.288191\tvalid_1's l1: 0.308738\n",
      "[844]\ttraining's l1: 0.288062\tvalid_1's l1: 0.308607\n",
      "[845]\ttraining's l1: 0.288005\tvalid_1's l1: 0.308568\n",
      "[846]\ttraining's l1: 0.287985\tvalid_1's l1: 0.308567\n",
      "[847]\ttraining's l1: 0.287923\tvalid_1's l1: 0.308529\n",
      "[848]\ttraining's l1: 0.287659\tvalid_1's l1: 0.308279\n",
      "[849]\ttraining's l1: 0.287554\tvalid_1's l1: 0.308187\n",
      "[850]\ttraining's l1: 0.287545\tvalid_1's l1: 0.308189\n",
      "[851]\ttraining's l1: 0.287508\tvalid_1's l1: 0.308168\n",
      "[852]\ttraining's l1: 0.287421\tvalid_1's l1: 0.308064\n",
      "[853]\ttraining's l1: 0.287329\tvalid_1's l1: 0.307984\n",
      "[854]\ttraining's l1: 0.287291\tvalid_1's l1: 0.307957\n",
      "[855]\ttraining's l1: 0.287047\tvalid_1's l1: 0.307685\n",
      "[856]\ttraining's l1: 0.28692\tvalid_1's l1: 0.307562\n",
      "[857]\ttraining's l1: 0.286715\tvalid_1's l1: 0.307367\n",
      "[858]\ttraining's l1: 0.286333\tvalid_1's l1: 0.30702\n",
      "[859]\ttraining's l1: 0.286281\tvalid_1's l1: 0.306983\n",
      "[860]\ttraining's l1: 0.286152\tvalid_1's l1: 0.306867\n",
      "[861]\ttraining's l1: 0.286055\tvalid_1's l1: 0.306788\n",
      "[862]\ttraining's l1: 0.28594\tvalid_1's l1: 0.30666\n",
      "[863]\ttraining's l1: 0.28581\tvalid_1's l1: 0.306553\n",
      "[864]\ttraining's l1: 0.285459\tvalid_1's l1: 0.306219\n",
      "[865]\ttraining's l1: 0.285394\tvalid_1's l1: 0.306165\n",
      "[866]\ttraining's l1: 0.285287\tvalid_1's l1: 0.306048\n",
      "[867]\ttraining's l1: 0.285272\tvalid_1's l1: 0.306042\n",
      "[868]\ttraining's l1: 0.285241\tvalid_1's l1: 0.306018\n",
      "[869]\ttraining's l1: 0.284905\tvalid_1's l1: 0.3057\n",
      "[870]\ttraining's l1: 0.284777\tvalid_1's l1: 0.305583\n",
      "[871]\ttraining's l1: 0.284613\tvalid_1's l1: 0.305448\n",
      "[872]\ttraining's l1: 0.284584\tvalid_1's l1: 0.305441\n",
      "[873]\ttraining's l1: 0.284459\tvalid_1's l1: 0.305328\n",
      "[874]\ttraining's l1: 0.284393\tvalid_1's l1: 0.305283\n",
      "[875]\ttraining's l1: 0.284368\tvalid_1's l1: 0.30526\n",
      "[876]\ttraining's l1: 0.284091\tvalid_1's l1: 0.305022\n",
      "[877]\ttraining's l1: 0.284069\tvalid_1's l1: 0.305011\n",
      "[878]\ttraining's l1: 0.283917\tvalid_1's l1: 0.30488\n",
      "[879]\ttraining's l1: 0.283716\tvalid_1's l1: 0.304751\n",
      "[880]\ttraining's l1: 0.283628\tvalid_1's l1: 0.304671\n",
      "[881]\ttraining's l1: 0.28352\tvalid_1's l1: 0.304573\n",
      "[882]\ttraining's l1: 0.283259\tvalid_1's l1: 0.304348\n",
      "[883]\ttraining's l1: 0.283196\tvalid_1's l1: 0.304289\n",
      "[884]\ttraining's l1: 0.282989\tvalid_1's l1: 0.304119\n",
      "[885]\ttraining's l1: 0.282705\tvalid_1's l1: 0.303859\n",
      "[886]\ttraining's l1: 0.28265\tvalid_1's l1: 0.30381\n",
      "[887]\ttraining's l1: 0.282582\tvalid_1's l1: 0.303759\n",
      "[888]\ttraining's l1: 0.282541\tvalid_1's l1: 0.303731\n",
      "[889]\ttraining's l1: 0.2825\tvalid_1's l1: 0.303703\n",
      "[890]\ttraining's l1: 0.282307\tvalid_1's l1: 0.303543\n",
      "[891]\ttraining's l1: 0.282237\tvalid_1's l1: 0.30349\n",
      "[892]\ttraining's l1: 0.281989\tvalid_1's l1: 0.303274\n",
      "[893]\ttraining's l1: 0.281927\tvalid_1's l1: 0.303219\n",
      "[894]\ttraining's l1: 0.28183\tvalid_1's l1: 0.303135\n",
      "[895]\ttraining's l1: 0.28168\tvalid_1's l1: 0.302996\n",
      "[896]\ttraining's l1: 0.281645\tvalid_1's l1: 0.302972\n",
      "[897]\ttraining's l1: 0.281582\tvalid_1's l1: 0.302934\n",
      "[898]\ttraining's l1: 0.281405\tvalid_1's l1: 0.302785\n",
      "[899]\ttraining's l1: 0.281309\tvalid_1's l1: 0.302705\n",
      "[900]\ttraining's l1: 0.281286\tvalid_1's l1: 0.302688\n",
      "[901]\ttraining's l1: 0.281056\tvalid_1's l1: 0.302476\n",
      "[902]\ttraining's l1: 0.281005\tvalid_1's l1: 0.302445\n",
      "[903]\ttraining's l1: 0.280936\tvalid_1's l1: 0.302393\n",
      "[904]\ttraining's l1: 0.280894\tvalid_1's l1: 0.302364\n",
      "[905]\ttraining's l1: 0.280836\tvalid_1's l1: 0.302304\n",
      "[906]\ttraining's l1: 0.280739\tvalid_1's l1: 0.302198\n",
      "[907]\ttraining's l1: 0.280651\tvalid_1's l1: 0.302115\n",
      "[908]\ttraining's l1: 0.280624\tvalid_1's l1: 0.302108\n",
      "[909]\ttraining's l1: 0.280608\tvalid_1's l1: 0.302103\n",
      "[910]\ttraining's l1: 0.280416\tvalid_1's l1: 0.301925\n",
      "[911]\ttraining's l1: 0.280382\tvalid_1's l1: 0.301906\n",
      "[912]\ttraining's l1: 0.280328\tvalid_1's l1: 0.301862\n",
      "[913]\ttraining's l1: 0.280266\tvalid_1's l1: 0.301777\n",
      "[914]\ttraining's l1: 0.280229\tvalid_1's l1: 0.301736\n",
      "[915]\ttraining's l1: 0.280053\tvalid_1's l1: 0.301586\n",
      "[916]\ttraining's l1: 0.279916\tvalid_1's l1: 0.301477\n",
      "[917]\ttraining's l1: 0.279892\tvalid_1's l1: 0.301465\n",
      "[918]\ttraining's l1: 0.279694\tvalid_1's l1: 0.301279\n",
      "[919]\ttraining's l1: 0.279673\tvalid_1's l1: 0.301262\n",
      "[920]\ttraining's l1: 0.279497\tvalid_1's l1: 0.301097\n",
      "[921]\ttraining's l1: 0.279443\tvalid_1's l1: 0.301054\n",
      "[922]\ttraining's l1: 0.279435\tvalid_1's l1: 0.301075\n",
      "[923]\ttraining's l1: 0.27922\tvalid_1's l1: 0.300873\n",
      "[924]\ttraining's l1: 0.279088\tvalid_1's l1: 0.300781\n",
      "[925]\ttraining's l1: 0.27894\tvalid_1's l1: 0.300649\n",
      "[926]\ttraining's l1: 0.278794\tvalid_1's l1: 0.300503\n",
      "[927]\ttraining's l1: 0.278719\tvalid_1's l1: 0.300434\n",
      "[928]\ttraining's l1: 0.278706\tvalid_1's l1: 0.300421\n",
      "[929]\ttraining's l1: 0.278628\tvalid_1's l1: 0.30035\n",
      "[930]\ttraining's l1: 0.2786\tvalid_1's l1: 0.300332\n",
      "[931]\ttraining's l1: 0.278435\tvalid_1's l1: 0.300191\n",
      "[932]\ttraining's l1: 0.278327\tvalid_1's l1: 0.300087\n",
      "[933]\ttraining's l1: 0.27832\tvalid_1's l1: 0.300091\n",
      "[934]\ttraining's l1: 0.278151\tvalid_1's l1: 0.299924\n",
      "[935]\ttraining's l1: 0.278012\tvalid_1's l1: 0.299825\n",
      "[936]\ttraining's l1: 0.277831\tvalid_1's l1: 0.299648\n",
      "[937]\ttraining's l1: 0.277582\tvalid_1's l1: 0.299379\n",
      "[938]\ttraining's l1: 0.277538\tvalid_1's l1: 0.299353\n",
      "[939]\ttraining's l1: 0.277503\tvalid_1's l1: 0.299326\n",
      "[940]\ttraining's l1: 0.27726\tvalid_1's l1: 0.299068\n",
      "[941]\ttraining's l1: 0.277236\tvalid_1's l1: 0.299053\n",
      "[942]\ttraining's l1: 0.277114\tvalid_1's l1: 0.298932\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[942]\ttraining's l1: 0.277114\tvalid_1's l1: 0.298932\n",
      "The rmlse of prediction is: 0.18511\n",
      "The rmlse of prediction is: 0.18502\n",
      "过拟合(-) 或 欠拟合(+)： 9.000000000000674e-05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-800460cef519>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrmsle1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_lgb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mrmsle2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_lgb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mrmsle3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_lgb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrmsle4\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_lgb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mrmsle5\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_lgb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-b6a8b9c4de2d>\u001b[0m in \u001b[0;36mget_lgb\u001b[1;34m(path, i)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'dataf_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my_eval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_off_eval\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   1522\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1523\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[1;32m-> 1524\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1650\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUnicodeWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mwriter_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1652\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1654\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36m_save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1752\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1753\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1754\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1756\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36m_save_chunk\u001b[1;34m(self, start_i, end_i)\u001b[0m\n\u001b[0;32m   1778\u001b[0m                                         quoting=self.quoting)\n\u001b[0;32m   1779\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1780\u001b[1;33m         \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_csv_rows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1782\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.write_csv_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path='../data/'\n",
    "rmsle0=get_lgb(path,0,N=942)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsle2=get_lgb(path,2,N=935)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsle1=get_lgb(path,1,N=1500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsle5=get_lgb(path,5,N=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsle3=get_lgb(path,3,N=700)\n",
    "rmsle4=get_lgb(path,4,N=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsle6=get_lgb(path,6,N=300) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
